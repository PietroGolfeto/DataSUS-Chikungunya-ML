{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a28f6cca-9c5e-4228-9248-dc682e75a670",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute '_no_nep50_warning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m                           \u001b[38;5;66;03m# For managing warnings\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# import shap                               # For SHAP (SHapley Additive exPlanations) values\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m                           \u001b[38;5;66;03m# For dealing with imbalanced datasets\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler   \u001b[38;5;66;03m# For oversampling\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler \u001b[38;5;66;03m# For undersampling\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/imblearn/combine/_smote_enn.py:9\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Authors: Guillaume Lemaitre <g.lemaitre58@gmail.com>\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#          Christos Aridas\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# License: MIT\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumbers\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/__init__.py:73\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     __check_build,\n\u001b[1;32m     71\u001b[0m     _distributor_init,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     76\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    115\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/__init__.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _joblib, metadata_routing\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/_chunking.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[1;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumbers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Integral, Real\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/scipy/sparse/__init__.py:300\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Original code by Travis Oliphant.\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# Modified and extended by Ed Schofield, Robert Cimrman,\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;66;03m# Nathan Bell, and Jake Vanderplas.\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/scipy/sparse/_base.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Base class for sparse matrices\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[1;32m      6\u001b[0m                        get_sum_dtype, isdense, isscalarlike,\n\u001b[1;32m      7\u001b[0m                        matrix, validateaxis, getdtype)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[1;32m     11\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124misspmatrix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missparse\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparray\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseWarning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSparseEfficiencyWarning\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/scipy/sparse/_sputils.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m prod\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m np_long, np_ulong\n\u001b[1;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupcast\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misscalarlike\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misintlike\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misshape\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missequence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misdense\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mismatrix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_sum_dtype\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbroadcast_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     17\u001b[0m supported_dtypes \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mbool_, np\u001b[38;5;241m.\u001b[39mbyte, np\u001b[38;5;241m.\u001b[39mubyte, np\u001b[38;5;241m.\u001b[39mshort, np\u001b[38;5;241m.\u001b[39mushort, np\u001b[38;5;241m.\u001b[39mintc,\n\u001b[1;32m     18\u001b[0m                     np\u001b[38;5;241m.\u001b[39muintc, np_long, np_ulong, np\u001b[38;5;241m.\u001b[39mlonglong, np\u001b[38;5;241m.\u001b[39mulonglong,\n\u001b[1;32m     19\u001b[0m                     np\u001b[38;5;241m.\u001b[39mfloat32, np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mlongdouble,\n\u001b[1;32m     20\u001b[0m                     np\u001b[38;5;241m.\u001b[39mcomplex64, np\u001b[38;5;241m.\u001b[39mcomplex128, np\u001b[38;5;241m.\u001b[39mclongdouble]\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/scipy/_lib/_util.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TypeAlias, TypeVar\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_namespace, is_numpy, xp_size\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docscrape\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionDoc, Parameter\n\u001b[1;32m     17\u001b[0m AxisError: \u001b[38;5;28mtype\u001b[39m[\u001b[38;5;167;01mException\u001b[39;00m]\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/scipy/_lib/_array_api.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnpt\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_api_compat\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_array_api_obj,\n\u001b[1;32m     20\u001b[0m     size \u001b[38;5;28;01mas\u001b[39;00m xp_size,\n\u001b[1;32m     21\u001b[0m     numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat,\n\u001b[1;32m     22\u001b[0m     device \u001b[38;5;28;01mas\u001b[39;00m xp_device,\n\u001b[1;32m     23\u001b[0m     is_numpy_namespace \u001b[38;5;28;01mas\u001b[39;00m is_numpy,\n\u001b[1;32m     24\u001b[0m     is_cupy_namespace \u001b[38;5;28;01mas\u001b[39;00m is_cupy,\n\u001b[1;32m     25\u001b[0m     is_torch_namespace \u001b[38;5;28;01mas\u001b[39;00m is_torch,\n\u001b[1;32m     26\u001b[0m     is_jax_namespace \u001b[38;5;28;01mas\u001b[39;00m is_jax,\n\u001b[1;32m     27\u001b[0m     is_array_api_strict_namespace \u001b[38;5;28;01mas\u001b[39;00m is_array_api_strict\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_asarray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray_namespace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massert_almost_equal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massert_array_almost_equal\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_xp_devices\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxp_take_along_axis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxp_unsupported_param_msg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxp_vector_norm\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     39\u001b[0m ]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# To enable array API and strict array-like input validation\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/scipy/_lib/array_api_compat/numpy/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# from numpy import * doesn't overwrite these builtin names\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;28mabs\u001b[39m, \u001b[38;5;28mmax\u001b[39m, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mround\u001b[39m \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/numpy/testing/__init__.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munittest\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TestCase\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _private\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (_assert_valid_refcount, _gen_alignment_data)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_private\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m extbuild\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/numpy/testing/_private/utils.py:469\u001b[0m\n\u001b[1;32m    465\u001b[0m         pprint\u001b[38;5;241m.\u001b[39mpprint(desired, msg)\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[0;32m--> 469\u001b[0m \u001b[38;5;129m@np\u001b[39m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_nep50_warning\u001b[49m()\n\u001b[1;32m    470\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21massert_almost_equal\u001b[39m(actual, desired, decimal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, err_msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    471\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;124;03m    Raises an AssertionError if two items are not equal up to desired\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m    precision.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    537\u001b[0m \n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m     __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Hide traceback for py.test\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/numpy/__init__.py:414\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute '_no_nep50_warning'"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "\n",
    "import pandas as pd                       # For data manipulation and analysis\n",
    "import numpy as np                        # For numerical computing\n",
    "import time                               # For tracking time\n",
    "import math                               # For mathematical operations\n",
    "import warnings                           # For managing warnings\n",
    "\n",
    "# import shap                               # For SHAP (SHapley Additive exPlanations) values\n",
    "\n",
    "import imblearn                           # For dealing with imbalanced datasets\n",
    "from imblearn.over_sampling import RandomOverSampler   # For oversampling\n",
    "from imblearn.under_sampling import RandomUnderSampler # For undersampling\n",
    "    \n",
    "\n",
    "import seaborn as sns                     # For statistical data visualization\n",
    "import matplotlib.pyplot as plt           # For creating visualizations\n",
    "import matplotlib.patches as mpatches     # For drawing patches in plots\n",
    "import matplotlib.colors as mcolors       # For defining custom colors in plots\n",
    "import matplotlib.ticker as ticker        # For formatting tick marks on plots\n",
    "from matplotlib.ticker import FuncFormatter         # For custom tick formatting\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler      # For feature scaling\n",
    "from sklearn.model_selection import (StratifiedKFold) # For splitting data into train and test sets\n",
    "\n",
    "from sklearn.metrics import (roc_auc_score,           # For evaluating model performance\n",
    "                             recall_score)   \n",
    "\n",
    "from sklearn.svm import SVC                           # For Support Vector Classifier\n",
    "from sklearn.linear_model import LogisticRegression   # For Logistic Regression Classifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, # For ensemble classifiers\n",
    "                              GradientBoostingClassifier,\n",
    "                              BaggingClassifier)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier      # For Multi-layer Perceptron Classifier\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import re\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ebf0c6-b108-4e25-9a3a-2da7f2717f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of folds for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
    "\n",
    "# Set preprocessing: StandardScaler for feature standardization\n",
    "preprocessing = StandardScaler()\n",
    "\n",
    "# Initialize KNNImputer with the specified number of neighbors\n",
    "imputer = KNNImputer(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a01e1-3ee8-4e70-b1ed-71d1795095ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing various classification algorithms\n",
    "\n",
    "algorithms = {\n",
    "    'svc_linear': SVC(probability=True, kernel='linear', random_state=0),\n",
    "    # Support Vector Classifier with linear kernel\n",
    "    \n",
    "    'svc_rbf': SVC(probability=True, kernel='rbf', random_state=0),\n",
    "    # Support Vector Classifier with radial basis function (RBF) kernel\n",
    "    \n",
    "    'random_forest': RandomForestClassifier(random_state=0),\n",
    "    # Random Forest Classifier\n",
    "    \n",
    "    'gradient_boosting': GradientBoostingClassifier(random_state=0),\n",
    "    # Gradient Boosting Classifier\n",
    "    \n",
    "    'logistic_regression': LogisticRegression(),\n",
    "    # Logistic Regression Classifier\n",
    "    \n",
    "    'bagging': BaggingClassifier(random_state=0),\n",
    "    # Bagging Classifier\n",
    "    \n",
    "    'mlp': MLPClassifier(random_state=0)\n",
    "    # Multi-layer Perceptron Classifier\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a580b6-211d-4a4d-85a0-e62afb275421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_sample(X, y):\n",
    "    '''\n",
    "    Receives a set of features and target feature separately. \n",
    "    Returns balanced data, with the same number of samples in both classes. \n",
    "    If the minority class is less than 5%, applies oversampling and undersampling. \n",
    "    Otherwise, applies only undersampling. \n",
    "    Parameters:\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            The feature matrix.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            The target variable.\n",
    "\n",
    "    Returns:\n",
    "        X_resampled : array-like, shape (n_samples_resampled, n_features)\n",
    "            The resampled feature matrix.\n",
    "        y_resampled : array-like, shape (n_samples_resampled,)\n",
    "            The resampled target variable.\n",
    "    '''\n",
    "    \n",
    "    # Define sampling strategies \n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority', random_state=1)\n",
    "    oversample = RandomOverSampler(sampling_strategy=0.2, random_state=1)\n",
    "    \n",
    "    # Identify the minority class\n",
    "    count_1 = (y == 1).sum()\n",
    "    count_0 = (y == 0).sum()\n",
    "    count_min = min(count_0, count_1)\n",
    "    count_max = max(count_0, count_1)\n",
    "\n",
    "    # Calculate the percentage of the minority class compared to the total number of instances\n",
    "    ratio = (count_min / count_max) \n",
    "    \n",
    "    # If the minority class is more than 60% of the majority class, do not apply any resampling technique\n",
    "    if ratio > 0.6: \n",
    "        X_resampled, y_resampled = X, y\n",
    "\n",
    "    # Check if the percentage of class 1 is at least 5% of the total number of instances\n",
    "    # If it is less than 5%, apply both over and under sampling    \n",
    "    else: \n",
    "        if ratio <= 0.2:\n",
    "            X_resampled, y_resampled = oversample.fit_resample(X, y)\n",
    "            X_resampled, y_resampled = undersample.fit_resample(X_resampled, y_resampled)\n",
    "\n",
    "        # Otherwise, apply only undersampling    \n",
    "        else:\n",
    "            X_resampled, y_resampled = undersample.fit_resample(X, y) \n",
    "        \n",
    "    return X_resampled, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7192dcb9-be8b-41ed-ac10-9302fad1a7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(data, n_neighbors=3):\n",
    "    \"\"\"\n",
    "    Impute missing values using the K-nearest neighbors algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input DataFrame with missing values.\n",
    "        n_neighbors (int, optional): Number of neighbors to use for imputation. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing values imputed using KNN.\n",
    "    \"\"\"\n",
    "    # Initialize KNNImputer with the specified number of neighbors\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "    # Perform imputation\n",
    "    imputed_data = imputer.fit_transform(data)\n",
    "\n",
    "    # Convert the imputed array back to a DataFrame\n",
    "    imputed_df = pd.DataFrame(imputed_data, columns=data.columns, index=data.index)\n",
    "\n",
    "    return imputed_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe8f23f-9dd9-4e7f-9844-7dd573137f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def evaluate_cv(X_train, y_train):\n",
    "    '''\n",
    "    Receives data to be evaluated and returns the average performance inside cross-validation, using 3 metrics.\n",
    "    Applies over-under sampling to get balanced datasets and standardizes features.\n",
    "    \n",
    "    Parameters:\n",
    "    data : DataFrame\n",
    "        The dataset containing features and the target variable.\n",
    "    \n",
    "    Returns:\n",
    "    df : DataFrame\n",
    "        A DataFrame containing the mean and standard deviation of each algorithm's performance across 5-fold cross-validation.\n",
    "        The performance metrics include AUC (mean and standard deviation), sensitivity (mean and standard deviation),\n",
    "        specificity (mean and standard deviation), prec_n (mean and standard deviation), and prec_p (mean and standard deviation).\n",
    "    '''\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # # Identify the target column\n",
    "    # target_feature = data.columns[-1]\n",
    "    \n",
    "    # # Separate features (X) and target (y)\n",
    "    # X = data.drop(columns=[target_feature])\n",
    "    # y = data[target_feature]\n",
    "    \n",
    "    # Initialize dictionaries to store metrics for each algorithm\n",
    "    sen = {}\n",
    "    spe = {}\n",
    "    auc = {}\n",
    "    prec_n = {}  # Negative precision\n",
    "    prec_p = {}  # Positive precision\n",
    "    \n",
    "    for algorithm in algorithms.keys():\n",
    "        sen[algorithm] = []\n",
    "        spe[algorithm] = []\n",
    "        auc[algorithm] = []\n",
    "        prec_n[algorithm] = []\n",
    "        prec_p[algorithm] = []\n",
    "\n",
    "    # Iterate through each round of the cross-validation\n",
    "    for train, test in kf.split(X_train, y_train):\n",
    "        # Allocate train and test data\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train], X_train.iloc[test]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        # # Apply over-under sampling\n",
    "        # X_train, y_train = data_sample(X_train, y_train)\n",
    "            \n",
    "        # X_train = imputer.fit_transform(X_train)\n",
    "        # X_test = imputer.transform(X_test)\n",
    "                \n",
    "        # # Standardize features\n",
    "        # X_train = preprocessing.fit_transform(X_train)\n",
    "        # X_test = preprocessing.transform(X_test)\n",
    "\n",
    "        # Iterate through each algorithm\n",
    "        for algorithm, (clf) in algorithms.items():\n",
    "            \n",
    "            clf.fit((X_train_fold), y_train_fold)\n",
    "\n",
    "            # Make predictions for the test data\n",
    "            y_pred = clf.predict(X_test_fold)\n",
    "\n",
    "            # Calculate sensitivity and specificity \n",
    "            recallscore = recall_score(y_test_fold, y_pred, labels=[0, 1], average=None)\n",
    "            sen[algorithm].append(recallscore[1])\n",
    "            spe[algorithm].append(recallscore[0])\n",
    "\n",
    "            # Calculate precision for each class\n",
    "            prec_score = precision_score(y_test_fold, y_pred, labels=[0, 1], average=None)\n",
    "            prec_n[algorithm].append(prec_score[0])\n",
    "            prec_p[algorithm].append(prec_score[1])\n",
    "\n",
    "            # Calculate the area under the ROC curve\n",
    "            aucscore = roc_auc_score(y_test_fold, (clf.predict_proba((X_test_fold)))[:, 1])     \n",
    "            auc[algorithm].append(aucscore)\n",
    "\n",
    "    # Create a DataFrame with the mean and standard deviation of each algorithm's performance across 5 folds \n",
    "    df = pd.DataFrame(columns=list(algorithms.keys()))\n",
    "\n",
    "    df.loc['auc (mean)'] = [np.mean(auc['svc_linear']), np.mean(auc['svc_rbf']), np.mean(auc['random_forest']), \n",
    "                            np.mean(auc['gradient_boosting']), np.mean(auc['logistic_regression']), \n",
    "                            np.mean(auc['bagging']), np.mean(auc['mlp'])]\n",
    "\n",
    "    df.loc['auc (stdev)'] = [np.std(auc['svc_linear']), np.std(auc['svc_rbf']), np.std(auc['random_forest']), \n",
    "                             np.std(auc['gradient_boosting']), np.std(auc['logistic_regression']), \n",
    "                             np.std(auc['bagging']), np.std(auc['mlp'])]\n",
    "\n",
    "    df.loc['rcl_1 (mean)'] = [np.mean(sen['svc_linear']), np.mean(sen['svc_rbf']), np.mean(sen['random_forest']), \n",
    "                            np.mean(sen['gradient_boosting']), np.mean(sen['logistic_regression']), \n",
    "                            np.mean(sen['bagging']), np.mean(sen['mlp'])]\n",
    "\n",
    "    df.loc['rcl_1 (stdev)'] = [np.std(sen['svc_linear']), np.std(sen['svc_rbf']), np.std(sen['random_forest']), \n",
    "                             np.std(sen['gradient_boosting']), np.std(sen['logistic_regression']), \n",
    "                             np.std(sen['bagging']), np.std(sen['mlp'])]\n",
    "\n",
    "    df.loc['rcl_0 (mean)'] = [np.mean(spe['svc_linear']), np.mean(spe['svc_rbf']), np.mean(spe['random_forest']), \n",
    "                            np.mean(spe['gradient_boosting']), np.mean(spe['logistic_regression']), \n",
    "                            np.mean(spe['bagging']), np.mean(spe['mlp'])]\n",
    "\n",
    "    df.loc['rcl_0 (stdev)'] = [np.std(spe['svc_linear']), np.std(spe['svc_rbf']), np.std(spe['random_forest']), \n",
    "                             np.std(spe['gradient_boosting']), np.std(spe['logistic_regression']), \n",
    "                             np.std(spe['bagging']), np.std(spe['mlp'])]\n",
    "\n",
    "    df.loc['prc_1 (mean)'] = [np.mean(prec_p['svc_linear']), np.mean(prec_p['svc_rbf']), np.mean(prec_p['random_forest']), \n",
    "                                 np.mean(prec_p['gradient_boosting']), np.mean(prec_p['logistic_regression']), \n",
    "                                 np.mean(prec_p['bagging']), np.mean(prec_p['mlp'])]\n",
    "\n",
    "    df.loc['prc_1 (stdev)'] = [np.std(prec_p['svc_linear']), np.std(prec_p['svc_rbf']), np.std(prec_p['random_forest']), \n",
    "                                  np.std(prec_p['gradient_boosting']), np.std(prec_p['logistic_regression']), \n",
    "                                  np.std(prec_p['bagging']), np.std(prec_p['mlp'])]\n",
    "\n",
    "    df.loc['prc_0 (mean)'] = [np.mean(prec_n['svc_linear']), np.mean(prec_n['svc_rbf']), np.mean(prec_n['random_forest']), \n",
    "                                 np.mean(prec_n['gradient_boosting']), np.mean(prec_n['logistic_regression']), \n",
    "                                 np.mean(prec_n['bagging']), np.mean(prec_n['mlp'])]\n",
    "\n",
    "    df.loc['prc_0 (stdev)'] = [np.std(prec_n['svc_linear']), np.std(prec_n['svc_rbf']), np.std(prec_n['random_forest']), \n",
    "                                  np.std(prec_n['gradient_boosting']), np.std(prec_n['logistic_regression']), \n",
    "                                  np.std(prec_n['bagging']), np.std(prec_n['mlp'])]\n",
    "\n",
    "    # Set caption for DataFrame\n",
    "    df = df.style.set_caption('Average performance and standard deviation among 5-fold cross-validation')\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the time taken\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    # Display the DataFrame\n",
    "    display(df)\n",
    "\n",
    "    # Print the total time taken to run cross-validation\n",
    "    print(f\"Total time taken to run cross-validation: {total_time:.2f} seconds\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e691d3fe-206c-4b5b-ad01-c57388737cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "def evaluate_external(data, data_test): \n",
    "    '''\n",
    "    Receives data and data_test to be evaluated and returns the average performance, using 3 metrics.\n",
    "    Applies over-under sampling to get balanced datasets and standardizes features.\n",
    "    \n",
    "    Parameters:\n",
    "    data : DataFrame\n",
    "        The training dataset containing features and the target variable.\n",
    "    data_test : DataFrame\n",
    "        The test dataset containing features and the target variable.\n",
    "    \n",
    "    Returns:\n",
    "    df : DataFrame\n",
    "        A DataFrame containing the mean performance of each algorithm across external validation.\n",
    "        The performance metrics include AUC (mean), sensitivity (mean), specificity (mean), prec_n (mean), and prec_p (mean).\n",
    "    '''\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Identify the target column\n",
    "    target_feature = data.columns[-1]\n",
    "    \n",
    "    # Separate features (X) and target (y) for training data\n",
    "    X = data.drop(columns=[target_feature])\n",
    "    y = data[target_feature]\n",
    "\n",
    "    # Separate features (X) and target (y) for test data\n",
    "    X_test = data_test.drop(columns=[target_feature])\n",
    "    y_test = data_test[target_feature]\n",
    "    \n",
    "    # Initialize dictionaries to store metrics for each algorithm\n",
    "    sen = {}\n",
    "    spe = {}\n",
    "    auc = {}\n",
    "    prec_n = {}  # Negative precision\n",
    "    prec_p = {}  # Positive precision\n",
    "    \n",
    "    for algorithm in algorithms.keys():\n",
    "        sen[algorithm] = []\n",
    "        spe[algorithm] = []\n",
    "        auc[algorithm] = []\n",
    "        prec_n[algorithm] = []\n",
    "        prec_p[algorithm] = []\n",
    "\n",
    "    # Apply over-under sampling to training data\n",
    "    X_train, y_train = data_sample(X, y)\n",
    "    #X_train = X\n",
    "    #y_train = y\n",
    "\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "    X_test = imputer.transform(X_test)\n",
    "  \n",
    "    # Apply preprocessing to both training and test data\n",
    "    X_train = preprocessing.fit_transform(X_train)\n",
    "    X_test = preprocessing.transform(X_test)\n",
    "  \n",
    "    # For each algorithm \n",
    "    for algorithm, (clf) in algorithms.items():\n",
    "        # Train model\n",
    "        clf.fit((X_train), y_train)\n",
    "\n",
    "        # Make predictions for the test data\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        # Calculate sensitivity and specificity \n",
    "        recallscore = recall_score(y_test, y_pred, labels=[0, 1], average=None)\n",
    "        sen[algorithm].append(recallscore[1])\n",
    "        spe[algorithm].append(recallscore[0])\n",
    "\n",
    "        # Calculate precision for each class\n",
    "        prec_score = precision_score(y_test, y_pred, labels=[0, 1], average=None)\n",
    "        prec_n[algorithm].append(prec_score[0])\n",
    "        prec_p[algorithm].append(prec_score[1])\n",
    "\n",
    "        # Calculate the area under the ROC curve\n",
    "        aucscore = roc_auc_score(y_test, (clf.predict_proba((X_test)))[:, 1])     \n",
    "        auc[algorithm].append(aucscore)\n",
    "    \n",
    "    # Create a DataFrame with the mean performance of each algorithm across the external validation\n",
    "    df = pd.DataFrame(columns=list(algorithms.keys()))\n",
    "\n",
    "    df.loc['auc'] = [np.mean(auc['svc_linear']), np.mean(auc['svc_rbf']), np.mean(auc['random_forest']), \n",
    "                            np.mean(auc['gradient_boosting']), np.mean(auc['logistic_regression']), \n",
    "                            np.mean(auc['bagging']), np.mean(auc['mlp'])]\n",
    "\n",
    "    df.loc['rcl_1'] = [np.mean(sen['svc_linear']), np.mean(sen['svc_rbf']), np.mean(sen['random_forest']), \n",
    "                            np.mean(sen['gradient_boosting']), np.mean(sen['logistic_regression']), \n",
    "                            np.mean(sen['bagging']), np.mean(sen['mlp'])]\n",
    "\n",
    "    df.loc['rcl_0'] = [np.mean(spe['svc_linear']), np.mean(spe['svc_rbf']), np.mean(spe['random_forest']), \n",
    "                            np.mean(spe['gradient_boosting']), np.mean(spe['logistic_regression']), \n",
    "                            np.mean(spe['bagging']), np.mean(spe['mlp'])]\n",
    "\n",
    "    df.loc['prc_1'] = [np.mean(prec_p['svc_linear']), np.mean(prec_p['svc_rbf']), np.mean(prec_p['random_forest']), \n",
    "                            np.mean(prec_p['gradient_boosting']), np.mean(prec_p['logistic_regression']), \n",
    "                            np.mean(prec_p['bagging']), np.mean(prec_p['mlp'])]\n",
    "\n",
    "    df.loc['prc_0'] = [np.mean(prec_n['svc_linear']), np.mean(prec_n['svc_rbf']), np.mean(prec_n['random_forest']), \n",
    "                            np.mean(prec_n['gradient_boosting']), np.mean(prec_n['logistic_regression']), \n",
    "                            np.mean(prec_n['bagging']), np.mean(prec_n['mlp'])]\n",
    "   \n",
    "    # Set caption for DataFrame\n",
    "    df = df.style.set_caption('Performance for external validation')\n",
    "   \n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate the time taken\n",
    "    total_time = end_time - start_time\n",
    "    \n",
    "    # Display the DataFrame\n",
    "    display(df)\n",
    "    \n",
    "    # Print the total time taken to run external-validation\n",
    "    print(f\"Total time taken to run external-validation: {total_time:.2f} seconds\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131b4f7-0713-4985-a0ee-c4c7f35bbcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('death_dengue_23.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a774b-b1b6-4c58-8fe0-167ce650fa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ita/tele/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/ita/tele/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/ita/tele/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/ita/tele/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/ita/tele/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_057c7\">\n",
       "  <caption>Average performance and standard deviation among 5-fold cross-validation</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_057c7_level0_col0\" class=\"col_heading level0 col0\" >svc_linear</th>\n",
       "      <th id=\"T_057c7_level0_col1\" class=\"col_heading level0 col1\" >svc_rbf</th>\n",
       "      <th id=\"T_057c7_level0_col2\" class=\"col_heading level0 col2\" >random_forest</th>\n",
       "      <th id=\"T_057c7_level0_col3\" class=\"col_heading level0 col3\" >gradient_boosting</th>\n",
       "      <th id=\"T_057c7_level0_col4\" class=\"col_heading level0 col4\" >logistic_regression</th>\n",
       "      <th id=\"T_057c7_level0_col5\" class=\"col_heading level0 col5\" >bagging</th>\n",
       "      <th id=\"T_057c7_level0_col6\" class=\"col_heading level0 col6\" >mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row0\" class=\"row_heading level0 row0\" >auc (mean)</th>\n",
       "      <td id=\"T_057c7_row0_col0\" class=\"data row0 col0\" >0.868875</td>\n",
       "      <td id=\"T_057c7_row0_col1\" class=\"data row0 col1\" >0.863518</td>\n",
       "      <td id=\"T_057c7_row0_col2\" class=\"data row0 col2\" >0.867892</td>\n",
       "      <td id=\"T_057c7_row0_col3\" class=\"data row0 col3\" >0.856056</td>\n",
       "      <td id=\"T_057c7_row0_col4\" class=\"data row0 col4\" >0.866408</td>\n",
       "      <td id=\"T_057c7_row0_col5\" class=\"data row0 col5\" >0.828921</td>\n",
       "      <td id=\"T_057c7_row0_col6\" class=\"data row0 col6\" >0.838820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row1\" class=\"row_heading level0 row1\" >auc (stdev)</th>\n",
       "      <td id=\"T_057c7_row1_col0\" class=\"data row1 col0\" >0.012221</td>\n",
       "      <td id=\"T_057c7_row1_col1\" class=\"data row1 col1\" >0.012315</td>\n",
       "      <td id=\"T_057c7_row1_col2\" class=\"data row1 col2\" >0.011804</td>\n",
       "      <td id=\"T_057c7_row1_col3\" class=\"data row1 col3\" >0.015567</td>\n",
       "      <td id=\"T_057c7_row1_col4\" class=\"data row1 col4\" >0.012723</td>\n",
       "      <td id=\"T_057c7_row1_col5\" class=\"data row1 col5\" >0.007793</td>\n",
       "      <td id=\"T_057c7_row1_col6\" class=\"data row1 col6\" >0.007771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row2\" class=\"row_heading level0 row2\" >rcl_1 (mean)</th>\n",
       "      <td id=\"T_057c7_row2_col0\" class=\"data row2 col0\" >0.811389</td>\n",
       "      <td id=\"T_057c7_row2_col1\" class=\"data row2 col1\" >0.822230</td>\n",
       "      <td id=\"T_057c7_row2_col2\" class=\"data row2 col2\" >0.836076</td>\n",
       "      <td id=\"T_057c7_row2_col3\" class=\"data row2 col3\" >0.812940</td>\n",
       "      <td id=\"T_057c7_row2_col4\" class=\"data row2 col4\" >0.802135</td>\n",
       "      <td id=\"T_057c7_row2_col5\" class=\"data row2 col5\" >0.746500</td>\n",
       "      <td id=\"T_057c7_row2_col6\" class=\"data row2 col6\" >0.795909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row3\" class=\"row_heading level0 row3\" >rcl_1 (stdev)</th>\n",
       "      <td id=\"T_057c7_row3_col0\" class=\"data row3 col0\" >0.017861</td>\n",
       "      <td id=\"T_057c7_row3_col1\" class=\"data row3 col1\" >0.026100</td>\n",
       "      <td id=\"T_057c7_row3_col2\" class=\"data row3 col2\" >0.034744</td>\n",
       "      <td id=\"T_057c7_row3_col3\" class=\"data row3 col3\" >0.034288</td>\n",
       "      <td id=\"T_057c7_row3_col4\" class=\"data row3 col4\" >0.021389</td>\n",
       "      <td id=\"T_057c7_row3_col5\" class=\"data row3 col5\" >0.027162</td>\n",
       "      <td id=\"T_057c7_row3_col6\" class=\"data row3 col6\" >0.040302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row4\" class=\"row_heading level0 row4\" >rcl_0 (mean)</th>\n",
       "      <td id=\"T_057c7_row4_col0\" class=\"data row4 col0\" >0.766919</td>\n",
       "      <td id=\"T_057c7_row4_col1\" class=\"data row4 col1\" >0.744366</td>\n",
       "      <td id=\"T_057c7_row4_col2\" class=\"data row4 col2\" >0.751807</td>\n",
       "      <td id=\"T_057c7_row4_col3\" class=\"data row4 col3\" >0.761277</td>\n",
       "      <td id=\"T_057c7_row4_col4\" class=\"data row4 col4\" >0.772597</td>\n",
       "      <td id=\"T_057c7_row4_col5\" class=\"data row4 col5\" >0.763146</td>\n",
       "      <td id=\"T_057c7_row4_col6\" class=\"data row4 col6\" >0.738706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row5\" class=\"row_heading level0 row5\" >rcl_0 (stdev)</th>\n",
       "      <td id=\"T_057c7_row5_col0\" class=\"data row5 col0\" >0.025435</td>\n",
       "      <td id=\"T_057c7_row5_col1\" class=\"data row5 col1\" >0.026123</td>\n",
       "      <td id=\"T_057c7_row5_col2\" class=\"data row5 col2\" >0.034013</td>\n",
       "      <td id=\"T_057c7_row5_col3\" class=\"data row5 col3\" >0.041539</td>\n",
       "      <td id=\"T_057c7_row5_col4\" class=\"data row5 col4\" >0.029652</td>\n",
       "      <td id=\"T_057c7_row5_col5\" class=\"data row5 col5\" >0.028837</td>\n",
       "      <td id=\"T_057c7_row5_col6\" class=\"data row5 col6\" >0.021904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row6\" class=\"row_heading level0 row6\" >prc_1 (mean)</th>\n",
       "      <td id=\"T_057c7_row6_col0\" class=\"data row6 col0\" >0.809419</td>\n",
       "      <td id=\"T_057c7_row6_col1\" class=\"data row6 col1\" >0.796775</td>\n",
       "      <td id=\"T_057c7_row6_col2\" class=\"data row6 col2\" >0.804427</td>\n",
       "      <td id=\"T_057c7_row6_col3\" class=\"data row6 col3\" >0.806676</td>\n",
       "      <td id=\"T_057c7_row6_col4\" class=\"data row6 col4\" >0.811704</td>\n",
       "      <td id=\"T_057c7_row6_col5\" class=\"data row6 col5\" >0.793789</td>\n",
       "      <td id=\"T_057c7_row6_col6\" class=\"data row6 col6\" >0.787572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row7\" class=\"row_heading level0 row7\" >prc_1 (stdev)</th>\n",
       "      <td id=\"T_057c7_row7_col0\" class=\"data row7 col0\" >0.013972</td>\n",
       "      <td id=\"T_057c7_row7_col1\" class=\"data row7 col1\" >0.015099</td>\n",
       "      <td id=\"T_057c7_row7_col2\" class=\"data row7 col2\" >0.018515</td>\n",
       "      <td id=\"T_057c7_row7_col3\" class=\"data row7 col3\" >0.023945</td>\n",
       "      <td id=\"T_057c7_row7_col4\" class=\"data row7 col4\" >0.016428</td>\n",
       "      <td id=\"T_057c7_row7_col5\" class=\"data row7 col5\" >0.015772</td>\n",
       "      <td id=\"T_057c7_row7_col6\" class=\"data row7 col6\" >0.011679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row8\" class=\"row_heading level0 row8\" >prc_0 (mean)</th>\n",
       "      <td id=\"T_057c7_row8_col0\" class=\"data row8 col0\" >0.770246</td>\n",
       "      <td id=\"T_057c7_row8_col1\" class=\"data row8 col1\" >0.775702</td>\n",
       "      <td id=\"T_057c7_row8_col2\" class=\"data row8 col2\" >0.792080</td>\n",
       "      <td id=\"T_057c7_row8_col3\" class=\"data row8 col3\" >0.771261</td>\n",
       "      <td id=\"T_057c7_row8_col4\" class=\"data row8 col4\" >0.763174</td>\n",
       "      <td id=\"T_057c7_row8_col5\" class=\"data row8 col5\" >0.712966</td>\n",
       "      <td id=\"T_057c7_row8_col6\" class=\"data row8 col6\" >0.750382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row9\" class=\"row_heading level0 row9\" >prc_0 (stdev)</th>\n",
       "      <td id=\"T_057c7_row9_col0\" class=\"data row9 col0\" >0.011471</td>\n",
       "      <td id=\"T_057c7_row9_col1\" class=\"data row9 col1\" >0.023467</td>\n",
       "      <td id=\"T_057c7_row9_col2\" class=\"data row9 col2\" >0.033217</td>\n",
       "      <td id=\"T_057c7_row9_col3\" class=\"data row9 col3\" >0.027854</td>\n",
       "      <td id=\"T_057c7_row9_col4\" class=\"data row9 col4\" >0.012732</td>\n",
       "      <td id=\"T_057c7_row9_col5\" class=\"data row9 col5\" >0.017508</td>\n",
       "      <td id=\"T_057c7_row9_col6\" class=\"data row9 col6\" >0.032924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x79be8ec73250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to run cross-validation: 109.09 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_057c7\">\n",
       "  <caption>Average performance and standard deviation among 5-fold cross-validation</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_057c7_level0_col0\" class=\"col_heading level0 col0\" >svc_linear</th>\n",
       "      <th id=\"T_057c7_level0_col1\" class=\"col_heading level0 col1\" >svc_rbf</th>\n",
       "      <th id=\"T_057c7_level0_col2\" class=\"col_heading level0 col2\" >random_forest</th>\n",
       "      <th id=\"T_057c7_level0_col3\" class=\"col_heading level0 col3\" >gradient_boosting</th>\n",
       "      <th id=\"T_057c7_level0_col4\" class=\"col_heading level0 col4\" >logistic_regression</th>\n",
       "      <th id=\"T_057c7_level0_col5\" class=\"col_heading level0 col5\" >bagging</th>\n",
       "      <th id=\"T_057c7_level0_col6\" class=\"col_heading level0 col6\" >mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row0\" class=\"row_heading level0 row0\" >auc (mean)</th>\n",
       "      <td id=\"T_057c7_row0_col0\" class=\"data row0 col0\" >0.868875</td>\n",
       "      <td id=\"T_057c7_row0_col1\" class=\"data row0 col1\" >0.863518</td>\n",
       "      <td id=\"T_057c7_row0_col2\" class=\"data row0 col2\" >0.867892</td>\n",
       "      <td id=\"T_057c7_row0_col3\" class=\"data row0 col3\" >0.856056</td>\n",
       "      <td id=\"T_057c7_row0_col4\" class=\"data row0 col4\" >0.866408</td>\n",
       "      <td id=\"T_057c7_row0_col5\" class=\"data row0 col5\" >0.828921</td>\n",
       "      <td id=\"T_057c7_row0_col6\" class=\"data row0 col6\" >0.838820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row1\" class=\"row_heading level0 row1\" >auc (stdev)</th>\n",
       "      <td id=\"T_057c7_row1_col0\" class=\"data row1 col0\" >0.012221</td>\n",
       "      <td id=\"T_057c7_row1_col1\" class=\"data row1 col1\" >0.012315</td>\n",
       "      <td id=\"T_057c7_row1_col2\" class=\"data row1 col2\" >0.011804</td>\n",
       "      <td id=\"T_057c7_row1_col3\" class=\"data row1 col3\" >0.015567</td>\n",
       "      <td id=\"T_057c7_row1_col4\" class=\"data row1 col4\" >0.012723</td>\n",
       "      <td id=\"T_057c7_row1_col5\" class=\"data row1 col5\" >0.007793</td>\n",
       "      <td id=\"T_057c7_row1_col6\" class=\"data row1 col6\" >0.007771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row2\" class=\"row_heading level0 row2\" >rcl_1 (mean)</th>\n",
       "      <td id=\"T_057c7_row2_col0\" class=\"data row2 col0\" >0.811389</td>\n",
       "      <td id=\"T_057c7_row2_col1\" class=\"data row2 col1\" >0.822230</td>\n",
       "      <td id=\"T_057c7_row2_col2\" class=\"data row2 col2\" >0.836076</td>\n",
       "      <td id=\"T_057c7_row2_col3\" class=\"data row2 col3\" >0.812940</td>\n",
       "      <td id=\"T_057c7_row2_col4\" class=\"data row2 col4\" >0.802135</td>\n",
       "      <td id=\"T_057c7_row2_col5\" class=\"data row2 col5\" >0.746500</td>\n",
       "      <td id=\"T_057c7_row2_col6\" class=\"data row2 col6\" >0.795909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row3\" class=\"row_heading level0 row3\" >rcl_1 (stdev)</th>\n",
       "      <td id=\"T_057c7_row3_col0\" class=\"data row3 col0\" >0.017861</td>\n",
       "      <td id=\"T_057c7_row3_col1\" class=\"data row3 col1\" >0.026100</td>\n",
       "      <td id=\"T_057c7_row3_col2\" class=\"data row3 col2\" >0.034744</td>\n",
       "      <td id=\"T_057c7_row3_col3\" class=\"data row3 col3\" >0.034288</td>\n",
       "      <td id=\"T_057c7_row3_col4\" class=\"data row3 col4\" >0.021389</td>\n",
       "      <td id=\"T_057c7_row3_col5\" class=\"data row3 col5\" >0.027162</td>\n",
       "      <td id=\"T_057c7_row3_col6\" class=\"data row3 col6\" >0.040302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row4\" class=\"row_heading level0 row4\" >rcl_0 (mean)</th>\n",
       "      <td id=\"T_057c7_row4_col0\" class=\"data row4 col0\" >0.766919</td>\n",
       "      <td id=\"T_057c7_row4_col1\" class=\"data row4 col1\" >0.744366</td>\n",
       "      <td id=\"T_057c7_row4_col2\" class=\"data row4 col2\" >0.751807</td>\n",
       "      <td id=\"T_057c7_row4_col3\" class=\"data row4 col3\" >0.761277</td>\n",
       "      <td id=\"T_057c7_row4_col4\" class=\"data row4 col4\" >0.772597</td>\n",
       "      <td id=\"T_057c7_row4_col5\" class=\"data row4 col5\" >0.763146</td>\n",
       "      <td id=\"T_057c7_row4_col6\" class=\"data row4 col6\" >0.738706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row5\" class=\"row_heading level0 row5\" >rcl_0 (stdev)</th>\n",
       "      <td id=\"T_057c7_row5_col0\" class=\"data row5 col0\" >0.025435</td>\n",
       "      <td id=\"T_057c7_row5_col1\" class=\"data row5 col1\" >0.026123</td>\n",
       "      <td id=\"T_057c7_row5_col2\" class=\"data row5 col2\" >0.034013</td>\n",
       "      <td id=\"T_057c7_row5_col3\" class=\"data row5 col3\" >0.041539</td>\n",
       "      <td id=\"T_057c7_row5_col4\" class=\"data row5 col4\" >0.029652</td>\n",
       "      <td id=\"T_057c7_row5_col5\" class=\"data row5 col5\" >0.028837</td>\n",
       "      <td id=\"T_057c7_row5_col6\" class=\"data row5 col6\" >0.021904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row6\" class=\"row_heading level0 row6\" >prc_1 (mean)</th>\n",
       "      <td id=\"T_057c7_row6_col0\" class=\"data row6 col0\" >0.809419</td>\n",
       "      <td id=\"T_057c7_row6_col1\" class=\"data row6 col1\" >0.796775</td>\n",
       "      <td id=\"T_057c7_row6_col2\" class=\"data row6 col2\" >0.804427</td>\n",
       "      <td id=\"T_057c7_row6_col3\" class=\"data row6 col3\" >0.806676</td>\n",
       "      <td id=\"T_057c7_row6_col4\" class=\"data row6 col4\" >0.811704</td>\n",
       "      <td id=\"T_057c7_row6_col5\" class=\"data row6 col5\" >0.793789</td>\n",
       "      <td id=\"T_057c7_row6_col6\" class=\"data row6 col6\" >0.787572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row7\" class=\"row_heading level0 row7\" >prc_1 (stdev)</th>\n",
       "      <td id=\"T_057c7_row7_col0\" class=\"data row7 col0\" >0.013972</td>\n",
       "      <td id=\"T_057c7_row7_col1\" class=\"data row7 col1\" >0.015099</td>\n",
       "      <td id=\"T_057c7_row7_col2\" class=\"data row7 col2\" >0.018515</td>\n",
       "      <td id=\"T_057c7_row7_col3\" class=\"data row7 col3\" >0.023945</td>\n",
       "      <td id=\"T_057c7_row7_col4\" class=\"data row7 col4\" >0.016428</td>\n",
       "      <td id=\"T_057c7_row7_col5\" class=\"data row7 col5\" >0.015772</td>\n",
       "      <td id=\"T_057c7_row7_col6\" class=\"data row7 col6\" >0.011679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row8\" class=\"row_heading level0 row8\" >prc_0 (mean)</th>\n",
       "      <td id=\"T_057c7_row8_col0\" class=\"data row8 col0\" >0.770246</td>\n",
       "      <td id=\"T_057c7_row8_col1\" class=\"data row8 col1\" >0.775702</td>\n",
       "      <td id=\"T_057c7_row8_col2\" class=\"data row8 col2\" >0.792080</td>\n",
       "      <td id=\"T_057c7_row8_col3\" class=\"data row8 col3\" >0.771261</td>\n",
       "      <td id=\"T_057c7_row8_col4\" class=\"data row8 col4\" >0.763174</td>\n",
       "      <td id=\"T_057c7_row8_col5\" class=\"data row8 col5\" >0.712966</td>\n",
       "      <td id=\"T_057c7_row8_col6\" class=\"data row8 col6\" >0.750382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_057c7_level0_row9\" class=\"row_heading level0 row9\" >prc_0 (stdev)</th>\n",
       "      <td id=\"T_057c7_row9_col0\" class=\"data row9 col0\" >0.011471</td>\n",
       "      <td id=\"T_057c7_row9_col1\" class=\"data row9 col1\" >0.023467</td>\n",
       "      <td id=\"T_057c7_row9_col2\" class=\"data row9 col2\" >0.033217</td>\n",
       "      <td id=\"T_057c7_row9_col3\" class=\"data row9 col3\" >0.027854</td>\n",
       "      <td id=\"T_057c7_row9_col4\" class=\"data row9 col4\" >0.012732</td>\n",
       "      <td id=\"T_057c7_row9_col5\" class=\"data row9 col5\" >0.017508</td>\n",
       "      <td id=\"T_057c7_row9_col6\" class=\"data row9 col6\" >0.032924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x79be8ec73250>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_cv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e4723-012c-4a64-8836-9fec6436b784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ita/tele/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3fa70\">\n",
       "  <caption>Performance for external validation</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3fa70_level0_col0\" class=\"col_heading level0 col0\" >svc_linear</th>\n",
       "      <th id=\"T_3fa70_level0_col1\" class=\"col_heading level0 col1\" >svc_rbf</th>\n",
       "      <th id=\"T_3fa70_level0_col2\" class=\"col_heading level0 col2\" >random_forest</th>\n",
       "      <th id=\"T_3fa70_level0_col3\" class=\"col_heading level0 col3\" >gradient_boosting</th>\n",
       "      <th id=\"T_3fa70_level0_col4\" class=\"col_heading level0 col4\" >logistic_regression</th>\n",
       "      <th id=\"T_3fa70_level0_col5\" class=\"col_heading level0 col5\" >bagging</th>\n",
       "      <th id=\"T_3fa70_level0_col6\" class=\"col_heading level0 col6\" >mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row0\" class=\"row_heading level0 row0\" >auc</th>\n",
       "      <td id=\"T_3fa70_row0_col0\" class=\"data row0 col0\" >0.848675</td>\n",
       "      <td id=\"T_3fa70_row0_col1\" class=\"data row0 col1\" >0.838825</td>\n",
       "      <td id=\"T_3fa70_row0_col2\" class=\"data row0 col2\" >0.839433</td>\n",
       "      <td id=\"T_3fa70_row0_col3\" class=\"data row0 col3\" >0.840177</td>\n",
       "      <td id=\"T_3fa70_row0_col4\" class=\"data row0 col4\" >0.852099</td>\n",
       "      <td id=\"T_3fa70_row0_col5\" class=\"data row0 col5\" >0.774700</td>\n",
       "      <td id=\"T_3fa70_row0_col6\" class=\"data row0 col6\" >0.800839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row1\" class=\"row_heading level0 row1\" >rcl_1</th>\n",
       "      <td id=\"T_3fa70_row1_col0\" class=\"data row1 col0\" >0.768559</td>\n",
       "      <td id=\"T_3fa70_row1_col1\" class=\"data row1 col1\" >0.794760</td>\n",
       "      <td id=\"T_3fa70_row1_col2\" class=\"data row1 col2\" >0.799127</td>\n",
       "      <td id=\"T_3fa70_row1_col3\" class=\"data row1 col3\" >0.781659</td>\n",
       "      <td id=\"T_3fa70_row1_col4\" class=\"data row1 col4\" >0.746725</td>\n",
       "      <td id=\"T_3fa70_row1_col5\" class=\"data row1 col5\" >0.641921</td>\n",
       "      <td id=\"T_3fa70_row1_col6\" class=\"data row1 col6\" >0.729258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row2\" class=\"row_heading level0 row2\" >rcl_0</th>\n",
       "      <td id=\"T_3fa70_row2_col0\" class=\"data row2 col0\" >0.784091</td>\n",
       "      <td id=\"T_3fa70_row2_col1\" class=\"data row2 col1\" >0.732955</td>\n",
       "      <td id=\"T_3fa70_row2_col2\" class=\"data row2 col2\" >0.738636</td>\n",
       "      <td id=\"T_3fa70_row2_col3\" class=\"data row2 col3\" >0.761364</td>\n",
       "      <td id=\"T_3fa70_row2_col4\" class=\"data row2 col4\" >0.784091</td>\n",
       "      <td id=\"T_3fa70_row2_col5\" class=\"data row2 col5\" >0.761364</td>\n",
       "      <td id=\"T_3fa70_row2_col6\" class=\"data row2 col6\" >0.755682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row3\" class=\"row_heading level0 row3\" >prc_1</th>\n",
       "      <td id=\"T_3fa70_row3_col0\" class=\"data row3 col0\" >0.822430</td>\n",
       "      <td id=\"T_3fa70_row3_col1\" class=\"data row3 col1\" >0.794760</td>\n",
       "      <td id=\"T_3fa70_row3_col2\" class=\"data row3 col2\" >0.799127</td>\n",
       "      <td id=\"T_3fa70_row3_col3\" class=\"data row3 col3\" >0.809955</td>\n",
       "      <td id=\"T_3fa70_row3_col4\" class=\"data row3 col4\" >0.818182</td>\n",
       "      <td id=\"T_3fa70_row3_col5\" class=\"data row3 col5\" >0.777778</td>\n",
       "      <td id=\"T_3fa70_row3_col6\" class=\"data row3 col6\" >0.795238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row4\" class=\"row_heading level0 row4\" >prc_0</th>\n",
       "      <td id=\"T_3fa70_row4_col0\" class=\"data row4 col0\" >0.722513</td>\n",
       "      <td id=\"T_3fa70_row4_col1\" class=\"data row4 col1\" >0.732955</td>\n",
       "      <td id=\"T_3fa70_row4_col2\" class=\"data row4 col2\" >0.738636</td>\n",
       "      <td id=\"T_3fa70_row4_col3\" class=\"data row4 col3\" >0.728261</td>\n",
       "      <td id=\"T_3fa70_row4_col4\" class=\"data row4 col4\" >0.704082</td>\n",
       "      <td id=\"T_3fa70_row4_col5\" class=\"data row4 col5\" >0.620370</td>\n",
       "      <td id=\"T_3fa70_row4_col6\" class=\"data row4 col6\" >0.682051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x73114b5ea6b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to run external-validation: 10.42 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_3fa70\">\n",
       "  <caption>Performance for external validation</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3fa70_level0_col0\" class=\"col_heading level0 col0\" >svc_linear</th>\n",
       "      <th id=\"T_3fa70_level0_col1\" class=\"col_heading level0 col1\" >svc_rbf</th>\n",
       "      <th id=\"T_3fa70_level0_col2\" class=\"col_heading level0 col2\" >random_forest</th>\n",
       "      <th id=\"T_3fa70_level0_col3\" class=\"col_heading level0 col3\" >gradient_boosting</th>\n",
       "      <th id=\"T_3fa70_level0_col4\" class=\"col_heading level0 col4\" >logistic_regression</th>\n",
       "      <th id=\"T_3fa70_level0_col5\" class=\"col_heading level0 col5\" >bagging</th>\n",
       "      <th id=\"T_3fa70_level0_col6\" class=\"col_heading level0 col6\" >mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row0\" class=\"row_heading level0 row0\" >auc</th>\n",
       "      <td id=\"T_3fa70_row0_col0\" class=\"data row0 col0\" >0.848675</td>\n",
       "      <td id=\"T_3fa70_row0_col1\" class=\"data row0 col1\" >0.838825</td>\n",
       "      <td id=\"T_3fa70_row0_col2\" class=\"data row0 col2\" >0.839433</td>\n",
       "      <td id=\"T_3fa70_row0_col3\" class=\"data row0 col3\" >0.840177</td>\n",
       "      <td id=\"T_3fa70_row0_col4\" class=\"data row0 col4\" >0.852099</td>\n",
       "      <td id=\"T_3fa70_row0_col5\" class=\"data row0 col5\" >0.774700</td>\n",
       "      <td id=\"T_3fa70_row0_col6\" class=\"data row0 col6\" >0.800839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row1\" class=\"row_heading level0 row1\" >rcl_1</th>\n",
       "      <td id=\"T_3fa70_row1_col0\" class=\"data row1 col0\" >0.768559</td>\n",
       "      <td id=\"T_3fa70_row1_col1\" class=\"data row1 col1\" >0.794760</td>\n",
       "      <td id=\"T_3fa70_row1_col2\" class=\"data row1 col2\" >0.799127</td>\n",
       "      <td id=\"T_3fa70_row1_col3\" class=\"data row1 col3\" >0.781659</td>\n",
       "      <td id=\"T_3fa70_row1_col4\" class=\"data row1 col4\" >0.746725</td>\n",
       "      <td id=\"T_3fa70_row1_col5\" class=\"data row1 col5\" >0.641921</td>\n",
       "      <td id=\"T_3fa70_row1_col6\" class=\"data row1 col6\" >0.729258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row2\" class=\"row_heading level0 row2\" >rcl_0</th>\n",
       "      <td id=\"T_3fa70_row2_col0\" class=\"data row2 col0\" >0.784091</td>\n",
       "      <td id=\"T_3fa70_row2_col1\" class=\"data row2 col1\" >0.732955</td>\n",
       "      <td id=\"T_3fa70_row2_col2\" class=\"data row2 col2\" >0.738636</td>\n",
       "      <td id=\"T_3fa70_row2_col3\" class=\"data row2 col3\" >0.761364</td>\n",
       "      <td id=\"T_3fa70_row2_col4\" class=\"data row2 col4\" >0.784091</td>\n",
       "      <td id=\"T_3fa70_row2_col5\" class=\"data row2 col5\" >0.761364</td>\n",
       "      <td id=\"T_3fa70_row2_col6\" class=\"data row2 col6\" >0.755682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row3\" class=\"row_heading level0 row3\" >prc_1</th>\n",
       "      <td id=\"T_3fa70_row3_col0\" class=\"data row3 col0\" >0.822430</td>\n",
       "      <td id=\"T_3fa70_row3_col1\" class=\"data row3 col1\" >0.794760</td>\n",
       "      <td id=\"T_3fa70_row3_col2\" class=\"data row3 col2\" >0.799127</td>\n",
       "      <td id=\"T_3fa70_row3_col3\" class=\"data row3 col3\" >0.809955</td>\n",
       "      <td id=\"T_3fa70_row3_col4\" class=\"data row3 col4\" >0.818182</td>\n",
       "      <td id=\"T_3fa70_row3_col5\" class=\"data row3 col5\" >0.777778</td>\n",
       "      <td id=\"T_3fa70_row3_col6\" class=\"data row3 col6\" >0.795238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3fa70_level0_row4\" class=\"row_heading level0 row4\" >prc_0</th>\n",
       "      <td id=\"T_3fa70_row4_col0\" class=\"data row4 col0\" >0.722513</td>\n",
       "      <td id=\"T_3fa70_row4_col1\" class=\"data row4 col1\" >0.732955</td>\n",
       "      <td id=\"T_3fa70_row4_col2\" class=\"data row4 col2\" >0.738636</td>\n",
       "      <td id=\"T_3fa70_row4_col3\" class=\"data row4 col3\" >0.728261</td>\n",
       "      <td id=\"T_3fa70_row4_col4\" class=\"data row4 col4\" >0.704082</td>\n",
       "      <td id=\"T_3fa70_row4_col5\" class=\"data row4 col5\" >0.620370</td>\n",
       "      <td id=\"T_3fa70_row4_col6\" class=\"data row4 col6\" >0.682051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x73114b5ea6b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv('death_dengue_24.csv')\n",
    "evaluate_external(data, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b6121c-30a7-4308-a612-031828306cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
