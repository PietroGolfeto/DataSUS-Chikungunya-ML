{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212b4563",
   "metadata": {},
   "source": [
    "## Outcome prediction after Chikungunya hospitalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a2939",
   "metadata": {},
   "source": [
    "#### MC853 - Unicamp\n",
    "\n",
    "- Leandro Henrique Silva Resende – 213437 \n",
    "\n",
    "- Pietro Grazzioli Golfeto – 223694 \n",
    "\n",
    "- Yvens Ian Prado Porto – 184031 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "35229f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "# We used Python 3.10.12\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import (StratifiedKFold)\n",
    "from sklearn.metrics import precision_score\n",
    "import time\n",
    "from sklearn.metrics import (roc_auc_score,           # For evaluating model performance\n",
    "                             recall_score)   \n",
    "from sklearn.svm import SVC                           # For Support Vector Classifier\n",
    "from sklearn.linear_model import LogisticRegression   # For Logistic Regression Classifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, # For ensemble classifiers\n",
    "                              GradientBoostingClassifier,\n",
    "                              BaggingClassifier)\n",
    "from sklearn.neural_network import MLPClassifier      # For Multi-layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "6f943f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the data (change according to your system)\n",
    "leandro_path = {\n",
    "    'X_train_path': '/home/leandro/Documentos/UNICAMP/MC853/DataSUS-Chikungunya-ML/datasets/X_train.csv',\n",
    "    'y_train_path': '/home/leandro/Documentos/UNICAMP/MC853/DataSUS-Chikungunya-ML/datasets/y_train.csv',\n",
    "    'X_test_path': '/home/leandro/Documentos/UNICAMP/MC853/DataSUS-Chikungunya-ML/datasets/X_test.csv',\n",
    "    'y_test_path': '/home/leandro/Documentos/UNICAMP/MC853/DataSUS-Chikungunya-ML/datasets/y_test.csv',\n",
    "}\n",
    "\n",
    "pietro_path = {\n",
    "    'X_train_path': '/home/pietro/Desktop/DataSUS-Chikungunya-ML/datasets/X_train.csv',\n",
    "    'y_train_path': '/home/pietro/Desktop/DataSUS-Chikungunya-ML/datasets/y_train.csv',\n",
    "    'X_test_path': '/home/pietro/Desktop/DataSUS-Chikungunya-ML/datasets/X_test.csv',\n",
    "    'y_test_path': '/home/pietro/Desktop/DataSUS-Chikungunya-ML/datasets/y_test.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ce9bad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path based on the user\n",
    "if os.path.isfile(leandro_path['X_train_path']):\n",
    "    path = leandro_path\n",
    "elif os.path.isfile(pietro_path['X_train_path']):\n",
    "    path = pietro_path\n",
    "else:\n",
    "    raise Exception('Path not found. Please check the paths in the script.')\n",
    "\n",
    "# Get CSV files path (modify to match your file path)\n",
    "X_train_path = os.path.expanduser(path['X_train_path'])\n",
    "y_train_path = os.path.expanduser(path['y_train_path'])\n",
    "X_test_path = os.path.expanduser(path['X_test_path'])\n",
    "y_test_path = os.path.expanduser(path['y_test_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "698622aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(X_train_path, low_memory=False)\n",
    "y_train = pd.read_csv(y_train_path, low_memory=False)\n",
    "X_test = pd.read_csv(X_test_path, low_memory=False)\n",
    "y_test = pd.read_csv(y_test_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f9c6587b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>PREGNANT</th>\n",
       "      <th>FEBRE</th>\n",
       "      <th>MIALGIA</th>\n",
       "      <th>CEFALEIA</th>\n",
       "      <th>EXANTEMA</th>\n",
       "      <th>VOMITO</th>\n",
       "      <th>NAUSEA</th>\n",
       "      <th>DOR_COSTAS</th>\n",
       "      <th>...</th>\n",
       "      <th>REGION_MIDWEST</th>\n",
       "      <th>REGION_SOUTHEAST</th>\n",
       "      <th>REGION_SOUTH</th>\n",
       "      <th>TIME_DIFF_DAYS</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>BLACK</th>\n",
       "      <th>YELLOW</th>\n",
       "      <th>BROWN</th>\n",
       "      <th>INDIGENOUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  GENDER  PREGNANT  FEBRE  MIALGIA  CEFALEIA  EXANTEMA  VOMITO  NAUSEA  \\\n",
       "0  10.0       0       0.0      1        1         1         1       0       1   \n",
       "1  29.0       1       0.0      1        1         1         1       0       1   \n",
       "2  11.0       1       0.0      1        1         1         0       0       0   \n",
       "3   5.0       1       0.0      1        0         1         0       0       1   \n",
       "4  11.0       1       0.0      1        1         1         0       0       0   \n",
       "\n",
       "   DOR_COSTAS  ...  REGION_MIDWEST  REGION_SOUTHEAST  REGION_SOUTH  \\\n",
       "0           1  ...               0                 0             0   \n",
       "1           1  ...               0                 0             0   \n",
       "2           0  ...               0                 0             0   \n",
       "3           0  ...               0                 0             0   \n",
       "4           0  ...               0                 0             0   \n",
       "\n",
       "   TIME_DIFF_DAYS  TIME  WHITE  BLACK  YELLOW  BROWN  INDIGENOUS  \n",
       "0               1    26      0      0       0      1           0  \n",
       "1               5    25      0      0       0      1           0  \n",
       "2               2    37      0      0       0      1           0  \n",
       "3              31    38      0      0       0      1           0  \n",
       "4               3    32      0      0       0      1           0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "74528375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'GENDER', 'PREGNANT', 'FEBRE', 'MIALGIA', 'CEFALEIA', 'EXANTEMA',\n",
       "       'VOMITO', 'NAUSEA', 'DOR_COSTAS', 'CONJUNTVIT', 'ARTRITE', 'ARTRALGIA',\n",
       "       'PETEQUIA_N', 'LEUCOPENIA', 'LACO', 'DOR_RETRO', 'DIABETES',\n",
       "       'HEMATOLOG', 'HEPATOPAT', 'RENAL', 'HIPERTENSA', 'ACIDO_PEPT',\n",
       "       'AUTO_IMUNE', 'CONFIRMED_CASE', 'CRITERIO', 'REGION_NORTH',\n",
       "       'REGION_NORTHEAST', 'REGION_MIDWEST', 'REGION_SOUTHEAST',\n",
       "       'REGION_SOUTH', 'TIME_DIFF_DAYS', 'TIME', 'WHITE', 'BLACK', 'YELLOW',\n",
       "       'BROWN', 'INDIGENOUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8c5bb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where TIME_DIFF_DAYS > 60 -> consider as outlier, before normalization\n",
    "scaler = RobustScaler()\n",
    "X_train[['AGE', 'TIME_DIFF_DAYS', 'TIME']] = scaler.fit_transform(X_train[['AGE', 'TIME_DIFF_DAYS', 'TIME']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "48ded60c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>TIME_DIFF_DAYS</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>21726.000000</td>\n",
       "      <td>21726.000000</td>\n",
       "      <td>21726.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.052730</td>\n",
       "      <td>0.572770</td>\n",
       "      <td>0.053436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.612048</td>\n",
       "      <td>2.019177</td>\n",
       "      <td>0.522004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.794872</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>-0.756345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.487179</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.426396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.573604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.256410</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>0.832487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AGE  TIME_DIFF_DAYS          TIME\n",
       "count  21726.000000    21726.000000  21726.000000\n",
       "mean       0.052730        0.572770      0.053436\n",
       "std        0.612048        2.019177      0.522004\n",
       "min       -0.794872       -0.750000     -0.756345\n",
       "25%       -0.487179       -0.375000     -0.426396\n",
       "50%        0.000000        0.000000      0.000000\n",
       "75%        0.512821        0.625000      0.573604\n",
       "max        2.256410       21.750000      0.832487"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['AGE', 'TIME_DIFF_DAYS', 'TIME']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "bc8c1912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>TIME_DIFF_DAYS</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.538462</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.624365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.051282</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.629442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.512821</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>-0.568528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666667</td>\n",
       "      <td>3.125</td>\n",
       "      <td>-0.563452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.512821</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.593909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE  TIME_DIFF_DAYS      TIME\n",
       "0 -0.538462          -0.625 -0.624365\n",
       "1 -0.051282          -0.125 -0.629442\n",
       "2 -0.512821          -0.500 -0.568528\n",
       "3 -0.666667           3.125 -0.563452\n",
       "4 -0.512821          -0.375 -0.593909"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['AGE', 'TIME_DIFF_DAYS', 'TIME']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "367cb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop CRITERIO column (not relevant with CONFIRMED_CASE)\n",
    "X_train['CRITERIO'].value_counts()\n",
    "X_train = X_train.drop(columns=['CRITERIO'])\n",
    "X_test = X_test.drop(columns=['CRITERIO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "986bfbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(data_train, data_test, n_neighbors=3):\n",
    "    \"\"\"\n",
    "    Impute missing values using the K-nearest neighbors algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input DataFrame with missing values.\n",
    "        n_neighbors (int, optional): Number of neighbors to use for imputation. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing values imputed using KNN.\n",
    "    \"\"\"\n",
    "    # Initialize KNNImputer with the specified number of neighbors\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "    # Perform imputation\n",
    "    imputed_data_train = imputer.fit_transform(data_train)\n",
    "    imputed_data_test = imputer.transform(data_test)\n",
    "\n",
    "    # Convert the imputed array back to a DataFrame\n",
    "    imputed_df_train = pd.DataFrame(imputed_data_train, columns=data_train.columns, index=data_train.index)\n",
    "    imputed_df_test = pd.DataFrame(imputed_data_test, columns=data_test.columns, index=data_test.index)\n",
    "\n",
    "    return imputed_df_train, imputed_df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5fc69a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = impute_missing(X_train, X_test, n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5771f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('o', SMOTE(sampling_strategy=0.5, random_state=42)),  # Increase minority to 50% of majority\n",
    "    ('u', RandomUnderSampler(sampling_strategy=1.0, random_state=42))  # Then balance both classes equally\n",
    "])\n",
    "\n",
    "X_train_balanced, y_train_balanced = pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "f4efc375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVOLUCAO    1586\n",
      "dtype: int64\n",
      "EVOLUCAO    10070\n",
      "dtype: int64\n",
      "EVOLUCAO\n",
      "0           10070\n",
      "1           10070\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.sum())\n",
    "print(y_train_balanced.sum())\n",
    "print(y_train_balanced.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "65d0926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of folds for cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "ab923537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dictionary containing various classification algorithms\n",
    "\n",
    "algorithms = {\n",
    "    'svc_linear': SVC(probability=True, kernel='linear', random_state=0),\n",
    "    # Support Vector Classifier with linear kernel\n",
    "    \n",
    "    'svc_rbf': SVC(probability=True, kernel='rbf', random_state=0),\n",
    "    # Support Vector Classifier with radial basis function (RBF) kernel\n",
    "    \n",
    "    'random_forest': RandomForestClassifier(random_state=0),\n",
    "    # Random Forest Classifier\n",
    "    \n",
    "    'gradient_boosting': GradientBoostingClassifier(random_state=0),\n",
    "    # Gradient Boosting Classifier\n",
    "    \n",
    "    'logistic_regression': LogisticRegression(),\n",
    "    # Logistic Regression Classifier\n",
    "    \n",
    "    'bagging': BaggingClassifier(random_state=0),\n",
    "    # Bagging Classifier\n",
    "    \n",
    "    'mlp': MLPClassifier(random_state=0)\n",
    "    # Multi-layer Perceptron Classifier\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5f4ef559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cv(X_train, y_train):\n",
    "    '''\n",
    "    Receives data to be evaluated and returns the average performance inside cross-validation, using 3 metrics.\n",
    "    Applies over-under sampling to get balanced datasets and standardizes features.\n",
    "    \n",
    "    Parameters:\n",
    "    data : DataFrame\n",
    "        The dataset containing features and the target variable.\n",
    "    \n",
    "    Returns:\n",
    "    df : DataFrame\n",
    "        A DataFrame containing the mean and standard deviation of each algorithm's performance across 5-fold cross-validation.\n",
    "        The performance metrics include AUC (mean and standard deviation), sensitivity (mean and standard deviation),\n",
    "        specificity (mean and standard deviation), prec_n (mean and standard deviation), and prec_p (mean and standard deviation).\n",
    "    '''\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # # Identify the target column\n",
    "    # target_feature = data.columns[-1]\n",
    "    \n",
    "    # # Separate features (X) and target (y)\n",
    "    # X = data.drop(columns=[target_feature])\n",
    "    # y = data[target_feature]\n",
    "    \n",
    "    # Initialize dictionaries to store metrics for each algorithm\n",
    "    sen = {}\n",
    "    spe = {}\n",
    "    auc = {}\n",
    "    prec_n = {}  # Negative precision\n",
    "    prec_p = {}  # Positive precision\n",
    "    \n",
    "    for algorithm in algorithms.keys():\n",
    "        sen[algorithm] = []\n",
    "        spe[algorithm] = []\n",
    "        auc[algorithm] = []\n",
    "        prec_n[algorithm] = []\n",
    "        prec_p[algorithm] = []\n",
    "\n",
    "    # Iterate through each round of the cross-validation\n",
    "    for train, test in kf.split(X_train, y_train):\n",
    "        # Allocate train and test data\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train], X_train.iloc[test]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train], y_train.iloc[test]\n",
    "\n",
    "        # # Apply over-under sampling\n",
    "        # X_train, y_train = data_sample(X_train, y_train)\n",
    "            \n",
    "        # X_train = imputer.fit_transform(X_train)\n",
    "        # X_test = imputer.transform(X_test)\n",
    "                \n",
    "        # # Standardize features\n",
    "        # X_train = preprocessing.fit_transform(X_train)\n",
    "        # X_test = preprocessing.transform(X_test)\n",
    "\n",
    "        # Iterate through each algorithm\n",
    "        for algorithm, (clf) in algorithms.items():\n",
    "            \n",
    "            clf.fit((X_train_fold), y_train_fold)\n",
    "\n",
    "            # Make predictions for the test data\n",
    "            y_pred = clf.predict(X_test_fold)\n",
    "\n",
    "            # Calculate sensitivity and specificity \n",
    "            recallscore = recall_score(y_test_fold, y_pred, labels=[0, 1], average=None)\n",
    "            sen[algorithm].append(recallscore[1])\n",
    "            spe[algorithm].append(recallscore[0])\n",
    "\n",
    "            # Calculate precision for each class\n",
    "            prec_score = precision_score(y_test_fold, y_pred, labels=[0, 1], average=None)\n",
    "            prec_n[algorithm].append(prec_score[0])\n",
    "            prec_p[algorithm].append(prec_score[1])\n",
    "\n",
    "            # Calculate the area under the ROC curve\n",
    "            aucscore = roc_auc_score(y_test_fold, (clf.predict_proba((X_test_fold)))[:, 1])     \n",
    "            auc[algorithm].append(aucscore)\n",
    "\n",
    "    # Create a DataFrame with the mean and standard deviation of each algorithm's performance across 5 folds \n",
    "    df = pd.DataFrame(columns=list(algorithms.keys()))\n",
    "\n",
    "    df.loc['auc (mean)'] = [np.mean(auc['svc_linear']), np.mean(auc['svc_rbf']), np.mean(auc['random_forest']), \n",
    "                            np.mean(auc['gradient_boosting']), np.mean(auc['logistic_regression']), \n",
    "                            np.mean(auc['bagging']), np.mean(auc['mlp'])]\n",
    "\n",
    "    df.loc['auc (stdev)'] = [np.std(auc['svc_linear']), np.std(auc['svc_rbf']), np.std(auc['random_forest']), \n",
    "                             np.std(auc['gradient_boosting']), np.std(auc['logistic_regression']), \n",
    "                             np.std(auc['bagging']), np.std(auc['mlp'])]\n",
    "\n",
    "    df.loc['rcl_1 (mean)'] = [np.mean(sen['svc_linear']), np.mean(sen['svc_rbf']), np.mean(sen['random_forest']), \n",
    "                            np.mean(sen['gradient_boosting']), np.mean(sen['logistic_regression']), \n",
    "                            np.mean(sen['bagging']), np.mean(sen['mlp'])]\n",
    "\n",
    "    df.loc['rcl_1 (stdev)'] = [np.std(sen['svc_linear']), np.std(sen['svc_rbf']), np.std(sen['random_forest']), \n",
    "                             np.std(sen['gradient_boosting']), np.std(sen['logistic_regression']), \n",
    "                             np.std(sen['bagging']), np.std(sen['mlp'])]\n",
    "\n",
    "    df.loc['rcl_0 (mean)'] = [np.mean(spe['svc_linear']), np.mean(spe['svc_rbf']), np.mean(spe['random_forest']), \n",
    "                            np.mean(spe['gradient_boosting']), np.mean(spe['logistic_regression']), \n",
    "                            np.mean(spe['bagging']), np.mean(spe['mlp'])]\n",
    "\n",
    "    df.loc['rcl_0 (stdev)'] = [np.std(spe['svc_linear']), np.std(spe['svc_rbf']), np.std(spe['random_forest']), \n",
    "                             np.std(spe['gradient_boosting']), np.std(spe['logistic_regression']), \n",
    "                             np.std(spe['bagging']), np.std(spe['mlp'])]\n",
    "\n",
    "    df.loc['prc_1 (mean)'] = [np.mean(prec_p['svc_linear']), np.mean(prec_p['svc_rbf']), np.mean(prec_p['random_forest']), \n",
    "                                 np.mean(prec_p['gradient_boosting']), np.mean(prec_p['logistic_regression']), \n",
    "                                 np.mean(prec_p['bagging']), np.mean(prec_p['mlp'])]\n",
    "\n",
    "    df.loc['prc_1 (stdev)'] = [np.std(prec_p['svc_linear']), np.std(prec_p['svc_rbf']), np.std(prec_p['random_forest']), \n",
    "                                  np.std(prec_p['gradient_boosting']), np.std(prec_p['logistic_regression']), \n",
    "                                  np.std(prec_p['bagging']), np.std(prec_p['mlp'])]\n",
    "\n",
    "    df.loc['prc_0 (mean)'] = [np.mean(prec_n['svc_linear']), np.mean(prec_n['svc_rbf']), np.mean(prec_n['random_forest']), \n",
    "                                 np.mean(prec_n['gradient_boosting']), np.mean(prec_n['logistic_regression']), \n",
    "                                 np.mean(prec_n['bagging']), np.mean(prec_n['mlp'])]\n",
    "\n",
    "    df.loc['prc_0 (stdev)'] = [np.std(prec_n['svc_linear']), np.std(prec_n['svc_rbf']), np.std(prec_n['random_forest']), \n",
    "                                  np.std(prec_n['gradient_boosting']), np.std(prec_n['logistic_regression']), \n",
    "                                  np.std(prec_n['bagging']), np.std(prec_n['mlp'])]\n",
    "\n",
    "    # Set caption for DataFrame\n",
    "    # df = df.style.set_caption('Average performance and standard deviation among 5-fold cross-validation')\n",
    "\n",
    "    # Record the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate the time taken\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    # Display the DataFrame\n",
    "    display(df)\n",
    "\n",
    "    # Print the total time taken to run cross-validation\n",
    "    print(f\"Total time taken to run cross-validation: {total_time:.2f} seconds\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "144275a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape y_train_balanced from column to 1D row\n",
    "# y_train_balanced = y_train_balanced.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f9b6d841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:878: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:878: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:878: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:878: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/ensemble/_bagging.py:878: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1124: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/pietro/Desktop/DataSUS-Chikungunya-ML/.venv/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svc_linear</th>\n",
       "      <th>svc_rbf</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>gradient_boosting</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>bagging</th>\n",
       "      <th>mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc (mean)</th>\n",
       "      <td>0.768986</td>\n",
       "      <td>0.906401</td>\n",
       "      <td>0.978204</td>\n",
       "      <td>0.953241</td>\n",
       "      <td>0.769402</td>\n",
       "      <td>0.957088</td>\n",
       "      <td>0.944427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc (stdev)</th>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.004981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcl_1 (mean)</th>\n",
       "      <td>0.719166</td>\n",
       "      <td>0.857498</td>\n",
       "      <td>0.906852</td>\n",
       "      <td>0.865243</td>\n",
       "      <td>0.714697</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.907547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcl_1 (stdev)</th>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcl_0 (mean)</th>\n",
       "      <td>0.684310</td>\n",
       "      <td>0.797021</td>\n",
       "      <td>0.957299</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>0.693843</td>\n",
       "      <td>0.928699</td>\n",
       "      <td>0.854816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcl_0 (stdev)</th>\n",
       "      <td>0.017330</td>\n",
       "      <td>0.015759</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.013229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc_1 (mean)</th>\n",
       "      <td>0.695118</td>\n",
       "      <td>0.808774</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.913552</td>\n",
       "      <td>0.700319</td>\n",
       "      <td>0.924558</td>\n",
       "      <td>0.862238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc_1 (stdev)</th>\n",
       "      <td>0.012475</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.010201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc_0 (mean)</th>\n",
       "      <td>0.708930</td>\n",
       "      <td>0.848351</td>\n",
       "      <td>0.911333</td>\n",
       "      <td>0.872014</td>\n",
       "      <td>0.708513</td>\n",
       "      <td>0.880281</td>\n",
       "      <td>0.902633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc_0 (stdev)</th>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.012736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               svc_linear   svc_rbf  random_forest  gradient_boosting  \\\n",
       "auc (mean)       0.768986  0.906401       0.978204           0.953241   \n",
       "auc (stdev)      0.009713  0.005190       0.001789           0.003231   \n",
       "rcl_1 (mean)     0.719166  0.857498       0.906852           0.865243   \n",
       "rcl_1 (stdev)    0.004830  0.007901       0.003242           0.002639   \n",
       "rcl_0 (mean)     0.684310  0.797021       0.957299           0.918073   \n",
       "rcl_0 (stdev)    0.017330  0.015759       0.001748           0.006081   \n",
       "prc_1 (mean)     0.695118  0.808774       0.955031           0.913552   \n",
       "prc_1 (stdev)    0.012475  0.012014       0.001811           0.005707   \n",
       "prc_0 (mean)     0.708930  0.848351       0.911333           0.872014   \n",
       "prc_0 (stdev)    0.007623  0.007363       0.002867           0.001711   \n",
       "\n",
       "               logistic_regression   bagging       mlp  \n",
       "auc (mean)                0.769402  0.957088  0.944427  \n",
       "auc (stdev)               0.010098  0.002737  0.004981  \n",
       "rcl_1 (mean)              0.714697  0.873684  0.907547  \n",
       "rcl_1 (stdev)             0.003841  0.003505  0.014063  \n",
       "rcl_0 (mean)              0.693843  0.928699  0.854816  \n",
       "rcl_0 (stdev)             0.018730  0.002905  0.013229  \n",
       "prc_1 (mean)              0.700319  0.924558  0.862238  \n",
       "prc_1 (stdev)             0.013403  0.002811  0.010201  \n",
       "prc_0 (mean)              0.708513  0.880281  0.902633  \n",
       "prc_0 (stdev)             0.007139  0.002878  0.012736  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time taken to run cross-validation: 374.58 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>svc_linear</th>\n",
       "      <th>svc_rbf</th>\n",
       "      <th>random_forest</th>\n",
       "      <th>gradient_boosting</th>\n",
       "      <th>logistic_regression</th>\n",
       "      <th>bagging</th>\n",
       "      <th>mlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>auc (mean)</th>\n",
       "      <td>0.768986</td>\n",
       "      <td>0.906401</td>\n",
       "      <td>0.978204</td>\n",
       "      <td>0.953241</td>\n",
       "      <td>0.769402</td>\n",
       "      <td>0.957088</td>\n",
       "      <td>0.944427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc (stdev)</th>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.010098</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.004981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcl_1 (mean)</th>\n",
       "      <td>0.719166</td>\n",
       "      <td>0.857498</td>\n",
       "      <td>0.906852</td>\n",
       "      <td>0.865243</td>\n",
       "      <td>0.714697</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.907547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcl_1 (stdev)</th>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.007901</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.014063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcl_0 (mean)</th>\n",
       "      <td>0.684310</td>\n",
       "      <td>0.797021</td>\n",
       "      <td>0.957299</td>\n",
       "      <td>0.918073</td>\n",
       "      <td>0.693843</td>\n",
       "      <td>0.928699</td>\n",
       "      <td>0.854816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcl_0 (stdev)</th>\n",
       "      <td>0.017330</td>\n",
       "      <td>0.015759</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.018730</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.013229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc_1 (mean)</th>\n",
       "      <td>0.695118</td>\n",
       "      <td>0.808774</td>\n",
       "      <td>0.955031</td>\n",
       "      <td>0.913552</td>\n",
       "      <td>0.700319</td>\n",
       "      <td>0.924558</td>\n",
       "      <td>0.862238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc_1 (stdev)</th>\n",
       "      <td>0.012475</td>\n",
       "      <td>0.012014</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.010201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc_0 (mean)</th>\n",
       "      <td>0.708930</td>\n",
       "      <td>0.848351</td>\n",
       "      <td>0.911333</td>\n",
       "      <td>0.872014</td>\n",
       "      <td>0.708513</td>\n",
       "      <td>0.880281</td>\n",
       "      <td>0.902633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prc_0 (stdev)</th>\n",
       "      <td>0.007623</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.012736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               svc_linear   svc_rbf  random_forest  gradient_boosting  \\\n",
       "auc (mean)       0.768986  0.906401       0.978204           0.953241   \n",
       "auc (stdev)      0.009713  0.005190       0.001789           0.003231   \n",
       "rcl_1 (mean)     0.719166  0.857498       0.906852           0.865243   \n",
       "rcl_1 (stdev)    0.004830  0.007901       0.003242           0.002639   \n",
       "rcl_0 (mean)     0.684310  0.797021       0.957299           0.918073   \n",
       "rcl_0 (stdev)    0.017330  0.015759       0.001748           0.006081   \n",
       "prc_1 (mean)     0.695118  0.808774       0.955031           0.913552   \n",
       "prc_1 (stdev)    0.012475  0.012014       0.001811           0.005707   \n",
       "prc_0 (mean)     0.708930  0.848351       0.911333           0.872014   \n",
       "prc_0 (stdev)    0.007623  0.007363       0.002867           0.001711   \n",
       "\n",
       "               logistic_regression   bagging       mlp  \n",
       "auc (mean)                0.769402  0.957088  0.944427  \n",
       "auc (stdev)               0.010098  0.002737  0.004981  \n",
       "rcl_1 (mean)              0.714697  0.873684  0.907547  \n",
       "rcl_1 (stdev)             0.003841  0.003505  0.014063  \n",
       "rcl_0 (mean)              0.693843  0.928699  0.854816  \n",
       "rcl_0 (stdev)             0.018730  0.002905  0.013229  \n",
       "prc_1 (mean)              0.700319  0.924558  0.862238  \n",
       "prc_1 (stdev)             0.013403  0.002811  0.010201  \n",
       "prc_0 (mean)              0.708513  0.880281  0.902633  \n",
       "prc_0 (stdev)             0.007139  0.002878  0.012736  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_cv(X_train_balanced, y_train_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecedb77c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
