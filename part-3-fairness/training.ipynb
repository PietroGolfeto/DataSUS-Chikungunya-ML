{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212b4563",
   "metadata": {},
   "source": [
    "## Outcome prediction after Chikungunya hospitalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a2939",
   "metadata": {},
   "source": [
    "#### MC853 - Unicamp\n",
    "\n",
    "- Leandro Henrique Silva Resende – 213437 \n",
    "\n",
    "- Pietro Grazzioli Golfeto – 223694 \n",
    "\n",
    "- Yvens Ian Prado Porto – 184031 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "35229f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "# We used Python 3.10.12\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import (\n",
    "    make_scorer, recall_score, precision_score, fbeta_score,\n",
    "    f1_score, balanced_accuracy_score, roc_auc_score,\n",
    "    average_precision_score\n",
    ")\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6f943f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the data (change according to your system)\n",
    "leandro_path = {\n",
    "    'X_train_path': '/home/leandro/Documentos/UNICAMP/MC853/DataSUS-Chikungunya-ML/datasets/X_train.csv',\n",
    "    'y_train_path': '/home/leandro/Documentos/UNICAMP/MC853/DataSUS-Chikungunya-ML/datasets/y_train.csv',\n",
    "    'X_test_path': '/home/leandro/Documentos/UNICAMP/MC853/DataSUS-Chikungunya-ML/datasets/X_test.csv',\n",
    "    'y_test_path': '/home/leandro/Documentos/UNICAMP/MC853/DataSUS-Chikungunya-ML/datasets/y_test.csv',\n",
    "}\n",
    "\n",
    "pietro_path = {\n",
    "    'X_train_path': '/home/pietro/Desktop/DataSUS-Chikungunya-ML/datasets/X_train.csv',\n",
    "    'y_train_path': '/home/pietro/Desktop/DataSUS-Chikungunya-ML/datasets/y_train.csv',\n",
    "    'X_test_path': '/home/pietro/Desktop/DataSUS-Chikungunya-ML/datasets/X_test.csv',\n",
    "    'y_test_path': '/home/pietro/Desktop/DataSUS-Chikungunya-ML/datasets/y_test.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "ce9bad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path based on the user\n",
    "if os.path.isfile(leandro_path['X_train_path']):\n",
    "    path = leandro_path\n",
    "elif os.path.isfile(pietro_path['X_train_path']):\n",
    "    path = pietro_path\n",
    "else:\n",
    "    raise Exception('Path not found. Please check the paths in the script.')\n",
    "\n",
    "# Get CSV files path (modify to match your file path)\n",
    "X_train_path = os.path.expanduser(path['X_train_path'])\n",
    "y_train_path = os.path.expanduser(path['y_train_path'])\n",
    "X_test_path = os.path.expanduser(path['X_test_path'])\n",
    "y_test_path = os.path.expanduser(path['y_test_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "698622aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(X_train_path, low_memory=False)\n",
    "y_train = pd.read_csv(y_train_path, low_memory=False).squeeze(\"columns\")\n",
    "X_test = pd.read_csv(X_test_path, low_memory=False)\n",
    "y_test = pd.read_csv(y_test_path, low_memory=False).squeeze(\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f9c6587b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AGE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "GENDER",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PREGNANT",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "FEBRE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "MIALGIA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CEFALEIA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "EXANTEMA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "VOMITO",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "NAUSEA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DOR_COSTAS",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CONJUNTVIT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ARTRITE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ARTRALGIA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "PETEQUIA_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LEUCOPENIA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "LACO",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DOR_RETRO",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "DIABETES",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HEMATOLOG",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HEPATOPAT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "RENAL",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "HIPERTENSA",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ACIDO_PEPT",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AUTO_IMUNE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "CONFIRMED_CASE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CRITERIO",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "REGION_NORTH",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "REGION_NORTHEAST",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "REGION_MIDWEST",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "REGION_SOUTHEAST",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "REGION_SOUTH",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TIME_DIFF_DAYS",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TIME",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "WHITE",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BLACK",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "YELLOW",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "BROWN",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "INDIGENOUS",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "a5865d03-bf1c-49a6-8f73-2fda40f2136d",
       "rows": [
        [
         "0",
         "10.0",
         "0",
         "0.0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "1.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "26",
         "0",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "1",
         "29.0",
         "1",
         "0.0",
         "1",
         "1",
         "1",
         "1",
         "0",
         "1",
         "1",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "1.0",
         "1.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "5",
         "25",
         "0",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "2",
         "11.0",
         "1",
         "0.0",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "2.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "2",
         "37",
         "0",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "3",
         "5.0",
         "1",
         "0.0",
         "1",
         "0",
         "1",
         "0",
         "0",
         "1",
         "0",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "1.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "31",
         "38",
         "0",
         "0",
         "0",
         "1",
         "0"
        ],
        [
         "4",
         "11.0",
         "1",
         "0.0",
         "1",
         "1",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "1.0",
         "1",
         "0",
         "0",
         "0",
         "0",
         "3",
         "32",
         "0",
         "0",
         "0",
         "1",
         "0"
        ]
       ],
       "shape": {
        "columns": 38,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>PREGNANT</th>\n",
       "      <th>FEBRE</th>\n",
       "      <th>MIALGIA</th>\n",
       "      <th>CEFALEIA</th>\n",
       "      <th>EXANTEMA</th>\n",
       "      <th>VOMITO</th>\n",
       "      <th>NAUSEA</th>\n",
       "      <th>DOR_COSTAS</th>\n",
       "      <th>...</th>\n",
       "      <th>REGION_MIDWEST</th>\n",
       "      <th>REGION_SOUTHEAST</th>\n",
       "      <th>REGION_SOUTH</th>\n",
       "      <th>TIME_DIFF_DAYS</th>\n",
       "      <th>TIME</th>\n",
       "      <th>WHITE</th>\n",
       "      <th>BLACK</th>\n",
       "      <th>YELLOW</th>\n",
       "      <th>BROWN</th>\n",
       "      <th>INDIGENOUS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  GENDER  PREGNANT  FEBRE  MIALGIA  CEFALEIA  EXANTEMA  VOMITO  NAUSEA  \\\n",
       "0  10.0       0       0.0      1        1         1         1       0       1   \n",
       "1  29.0       1       0.0      1        1         1         1       0       1   \n",
       "2  11.0       1       0.0      1        1         1         0       0       0   \n",
       "3   5.0       1       0.0      1        0         1         0       0       1   \n",
       "4  11.0       1       0.0      1        1         1         0       0       0   \n",
       "\n",
       "   DOR_COSTAS  ...  REGION_MIDWEST  REGION_SOUTHEAST  REGION_SOUTH  \\\n",
       "0           1  ...               0                 0             0   \n",
       "1           1  ...               0                 0             0   \n",
       "2           0  ...               0                 0             0   \n",
       "3           0  ...               0                 0             0   \n",
       "4           0  ...               0                 0             0   \n",
       "\n",
       "   TIME_DIFF_DAYS  TIME  WHITE  BLACK  YELLOW  BROWN  INDIGENOUS  \n",
       "0               1    26      0      0       0      1           0  \n",
       "1               5    25      0      0       0      1           0  \n",
       "2               2    37      0      0       0      1           0  \n",
       "3              31    38      0      0       0      1           0  \n",
       "4               3    32      0      0       0      1           0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "74528375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'GENDER', 'PREGNANT', 'FEBRE', 'MIALGIA', 'CEFALEIA', 'EXANTEMA',\n",
       "       'VOMITO', 'NAUSEA', 'DOR_COSTAS', 'CONJUNTVIT', 'ARTRITE', 'ARTRALGIA',\n",
       "       'PETEQUIA_N', 'LEUCOPENIA', 'LACO', 'DOR_RETRO', 'DIABETES',\n",
       "       'HEMATOLOG', 'HEPATOPAT', 'RENAL', 'HIPERTENSA', 'ACIDO_PEPT',\n",
       "       'AUTO_IMUNE', 'CONFIRMED_CASE', 'CRITERIO', 'REGION_NORTH',\n",
       "       'REGION_NORTHEAST', 'REGION_MIDWEST', 'REGION_SOUTHEAST',\n",
       "       'REGION_SOUTH', 'TIME_DIFF_DAYS', 'TIME', 'WHITE', 'BLACK', 'YELLOW',\n",
       "       'BROWN', 'INDIGENOUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "bc8c1912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "AGE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TIME_DIFF_DAYS",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "TIME",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "f8ade028-1f38-4b0c-a178-a92399151fd8",
       "rows": [
        [
         "0",
         "10.0",
         "1",
         "26"
        ],
        [
         "1",
         "29.0",
         "5",
         "25"
        ],
        [
         "2",
         "11.0",
         "2",
         "37"
        ],
        [
         "3",
         "5.0",
         "31",
         "38"
        ],
        [
         "4",
         "11.0",
         "3",
         "32"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>TIME_DIFF_DAYS</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>31</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGE  TIME_DIFF_DAYS  TIME\n",
       "0  10.0               1    26\n",
       "1  29.0               5    25\n",
       "2  11.0               2    37\n",
       "3   5.0              31    38\n",
       "4  11.0               3    32"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[['AGE', 'TIME_DIFF_DAYS', 'TIME']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "367cb46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop CRITERIO column (not relevant alongside CONFIRMED_CASE)\n",
    "X_train['CRITERIO'].value_counts()\n",
    "X_train = X_train.drop(columns=['CRITERIO'])\n",
    "X_test = X_test.drop(columns=['CRITERIO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "986bfbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing(data_train, data_test, n_neighbors=3):\n",
    "    \"\"\"\n",
    "    Impute missing values using the K-nearest neighbors algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): Input DataFrame with missing values.\n",
    "        n_neighbors (int, optional): Number of neighbors to use for imputation. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with missing values imputed using KNN.\n",
    "    \"\"\"\n",
    "    # Initialize KNNImputer with the specified number of neighbors\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "\n",
    "    # Perform imputation\n",
    "    imputed_data_train = imputer.fit_transform(data_train)\n",
    "    imputed_data_test = imputer.transform(data_test)\n",
    "\n",
    "    # Convert the imputed array back to a DataFrame\n",
    "    imputed_df_train = pd.DataFrame(imputed_data_train, columns=data_train.columns, index=data_train.index)\n",
    "    imputed_df_test = pd.DataFrame(imputed_data_test, columns=data_test.columns, index=data_test.index)\n",
    "\n",
    "    return imputed_df_train, imputed_df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5fc69a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values in the training and test sets using KNN\n",
    "X_train, X_test = impute_missing(X_train, X_test, n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8ffbe17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(X, y, col, thresh):\n",
    "    \"\"\"\n",
    "    Keep only rows where X[col] <= thresh and drop the others in both X and its matching y.\n",
    "    \"\"\"\n",
    "    keep_mask = X[col] <= thresh          # boolean mask\n",
    "    X_clean   = X.loc[keep_mask].reset_index(drop=True)\n",
    "    y_clean   = y.loc[keep_mask].reset_index(drop=True)\n",
    "    print(f\"Removed {len(X) - len(X_clean)} outliers from {col} > {thresh}\")\n",
    "    return X_clean, y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b8a2e43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:\n",
      "Removed 743 outliers from TIME_DIFF_DAYS > 45\n",
      "Test set:\n",
      "Removed 239 outliers from TIME_DIFF_DAYS > 45\n"
     ]
    }
   ],
   "source": [
    "# Remove rows where TIME_DIFF_DAYS > 45 -> consider as outliers\n",
    "print(\"Train set:\")\n",
    "X_train, y_train = remove_outliers(X=X_train, y=y_train, col='TIME_DIFF_DAYS', thresh=45)\n",
    "\n",
    "print(\"Test set:\")\n",
    "X_test , y_test  = remove_outliers(X=X_test , y=y_test, col='TIME_DIFF_DAYS', thresh=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f971f511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AGE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TIME_DIFF_DAYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TIME",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "8d3b73c5-7ba9-4d19-8a68-f54d796a6230",
       "rows": [
        [
         "count",
         "20983.0",
         "20983.0",
         "20983.0"
        ],
        [
         "mean",
         "32.964828670828766",
         "8.174522232283277",
         "160.61497402659296"
        ],
        [
         "std",
         "23.83860521180584",
         "8.008933922254029",
         "102.7989279932754"
        ],
        [
         "min",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "25%",
         "12.0",
         "3.0",
         "66.0"
        ],
        [
         "50%",
         "30.0",
         "6.0",
         "155.0"
        ],
        [
         "75%",
         "51.0",
         "10.0",
         "263.0"
        ],
        [
         "max",
         "119.0",
         "45.0",
         "313.0"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>TIME_DIFF_DAYS</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20983.000000</td>\n",
       "      <td>20983.000000</td>\n",
       "      <td>20983.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.964829</td>\n",
       "      <td>8.174522</td>\n",
       "      <td>160.614974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.838605</td>\n",
       "      <td>8.008934</td>\n",
       "      <td>102.798928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>263.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>119.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>313.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AGE  TIME_DIFF_DAYS          TIME\n",
       "count  20983.000000    20983.000000  20983.000000\n",
       "mean      32.964829        8.174522    160.614974\n",
       "std       23.838605        8.008934    102.798928\n",
       "min        0.000000        0.000000      0.000000\n",
       "25%       12.000000        3.000000     66.000000\n",
       "50%       30.000000        6.000000    155.000000\n",
       "75%       51.000000       10.000000    263.000000\n",
       "max      119.000000       45.000000    313.000000"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuos features before scaling\n",
    "X_train[['AGE', 'TIME_DIFF_DAYS', 'TIME']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b2da7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using RobustScaler\n",
    "# RobustScaler is robust to outliers and scales features to the interquartile range\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Fit the scaler on the training data and transform both training and test data\n",
    "# Note: We only fit the scaler on the training data to avoid data leakage\n",
    "# The scaler will be applied to the test data using the same parameters learned from the training data\n",
    "X_train[['AGE', 'TIME_DIFF_DAYS', 'TIME']] = scaler.fit_transform(X_train[['AGE', 'TIME_DIFF_DAYS', 'TIME']])\n",
    "X_test[['AGE', 'TIME_DIFF_DAYS', 'TIME']] = scaler.transform(X_test[['AGE', 'TIME_DIFF_DAYS', 'TIME']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "abcbcd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "AGE",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TIME_DIFF_DAYS",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "TIME",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "d3886bce-7635-445c-a5ea-380d68b7099e",
       "rows": [
        [
         "count",
         "20983.0",
         "20983.0",
         "20983.0"
        ],
        [
         "mean",
         "0.07602124796996837",
         "0.3106460331833253",
         "0.0285024062263602"
        ],
        [
         "std",
         "0.6112462874822011",
         "1.1441334174648612",
         "0.5218219695090122"
        ],
        [
         "min",
         "-0.7692307692307693",
         "-0.8571428571428571",
         "-0.7868020304568528"
        ],
        [
         "25%",
         "-0.46153846153846156",
         "-0.42857142857142855",
         "-0.4517766497461929"
        ],
        [
         "50%",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "75%",
         "0.5384615384615384",
         "0.5714285714285714",
         "0.5482233502538071"
        ],
        [
         "max",
         "2.282051282051282",
         "5.571428571428571",
         "0.8020304568527918"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>TIME_DIFF_DAYS</th>\n",
       "      <th>TIME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20983.000000</td>\n",
       "      <td>20983.000000</td>\n",
       "      <td>20983.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.076021</td>\n",
       "      <td>0.310646</td>\n",
       "      <td>0.028502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.611246</td>\n",
       "      <td>1.144133</td>\n",
       "      <td>0.521822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.769231</td>\n",
       "      <td>-0.857143</td>\n",
       "      <td>-0.786802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.461538</td>\n",
       "      <td>-0.428571</td>\n",
       "      <td>-0.451777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.548223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.282051</td>\n",
       "      <td>5.571429</td>\n",
       "      <td>0.802030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AGE  TIME_DIFF_DAYS          TIME\n",
       "count  20983.000000    20983.000000  20983.000000\n",
       "mean       0.076021        0.310646      0.028502\n",
       "std        0.611246        1.144133      0.521822\n",
       "min       -0.769231       -0.857143     -0.786802\n",
       "25%       -0.461538       -0.428571     -0.451777\n",
       "50%        0.000000        0.000000      0.000000\n",
       "75%        0.538462        0.571429      0.548223\n",
       "max        2.282051        5.571429      0.802030"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuos features after scaling\n",
    "X_train[['AGE', 'TIME_DIFF_DAYS', 'TIME']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f4efc375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set target distribution: \n",
      "EVOLUCAO\n",
      "0    0.928418\n",
      "1    0.071582\n",
      "Name: proportion, dtype: float64,\n",
      "\n",
      "Test set target distribution: \n",
      "EVOLUCAO\n",
      "0    0.924028\n",
      "1    0.075972\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of the target variable in the training set\n",
    "print(f\"Train set target distribution: \\n{y_train.value_counts(normalize=True)},\\n\")\n",
    "\n",
    "# Check the distribution of the target variable in the test set\n",
    "print(f\"Test set target distribution: \\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5771f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the resampling pipeline that will be used on training data during cross-validation (not on validation data)\n",
    "# SMOTE (Synthetic Minority Over-sampling Technique) is used to generate synthetic samples for the minority class\n",
    "# RandomUnderSampler is used to randomly under-sample the majority class\n",
    "resample_pipe = Pipeline(steps=[\n",
    "    ('o', SMOTE(sampling_strategy=0.4, random_state=42)),\n",
    "    ('u', RandomUnderSampler(sampling_strategy=1.0, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "65d0926d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of folds for cross-validation\n",
    "# StratifiedKFold ensures that each fold has the same proportion of classes as the entire dataset\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d0c5d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter grids for each model to be used in GridSearchCV\n",
    "param_grids = {\n",
    "    'knn': {\n",
    "         'n_neighbors': [1, 3, 5, 10],\n",
    "         'p': [1, 2],\n",
    "         'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "         # Use 'balanced' or a dict assigning more weight to class 1 (assuming class 0 weight stays 1)\n",
    "         'class_weight': ['balanced', {0: 1, 1: 2}, {0: 1, 1: 3}]\n",
    "    },\n",
    "    'random_forest': {\n",
    "         'n_estimators': [10, 100, 200],\n",
    "         'max_depth': [10, 50],\n",
    "         'min_samples_split': [2, 10, 30],\n",
    "         'class_weight': ['balanced', {0: 1, 1: 2}, {0: 1, 1: 3}]     \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e959a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base estimators models to be trained\n",
    "# Each model will be trained using GridSearchCV with the specified hyperparameter grid\n",
    "base_estimators = {\n",
    "    'random_forest': RandomForestClassifier(random_state=0, n_jobs=-1),\n",
    "    'logistic_regression': LogisticRegression(random_state=0, n_jobs=-1),\n",
    "    'knn': KNeighborsClassifier(n_jobs=-1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c2d6d7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scorers for both classes\n",
    "scoring_dict = {\n",
    "    # class-1 (positive) metrics\n",
    "    \"recall_1\"    : make_scorer(recall_score,    pos_label=1),\n",
    "    \"precision_1\" : make_scorer(precision_score, pos_label=1, zero_division=0),\n",
    "    \"f1_1\"        : make_scorer(f1_score,        pos_label=1, zero_division=0),\n",
    "    \"f2_1\"        : make_scorer(fbeta_score,     beta=2, pos_label=1, zero_division=0),\n",
    "\n",
    "    # class-0 (negative) metrics\n",
    "    \"recall_0\"    : make_scorer(recall_score,    pos_label=0),\n",
    "    \"precision_0\" : make_scorer(precision_score, pos_label=0, zero_division=0),\n",
    "    \"f1_0\"        : make_scorer(f1_score,        pos_label=0, zero_division=0),\n",
    "    \"f2_0\"        : make_scorer(fbeta_score,     beta=2, pos_label=0, zero_division=0),\n",
    "\n",
    "    # class-agnostic metrics\n",
    "    \"balanced_acc\": \"balanced_accuracy\",\n",
    "    \"roc_auc\"     : \"roc_auc\",\n",
    "    \"pr_auc\"      : \"average_precision\"\n",
    "}\n",
    "\n",
    "# Use recall of class 1 as the main scoring metric for model evaluation in GridSearchCV\n",
    "# Recall is the ratio of true positives to the sum of true positives and false negatives\n",
    "# It is a good metric to use when the cost of false negatives is high\n",
    "# For example, in a medical diagnosis scenario, we want to minimize the number of false negatives\n",
    "# (i.e., we want to correctly identify as many positive cases as possible)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "381c685f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Build one GridSearchCV wrapper per base model\n",
    "  • Uses the algorithm-specific hyper-parameter grids defined in param_grids\n",
    "  • Shares the same StratifiedKFold object (kf) → every model sees identical\n",
    "    train/validation splits during the search\n",
    "  • Optimize models ONLY on recall of the positive class (label = 1) because\n",
    "    missing a true-positive chikungunya case is the costliest error\n",
    "  • refit='recall_1' ⇒ once the best hyper-params are found inside CV,\n",
    "    retrain a fresh model on the entire (SMOTE+undersampled) training set.\n",
    "    This ensures: (i) no data leakage; (ii) every final model has seen all\n",
    "    available training samples before we evaluate on X_test later.\n",
    "Result: `algorithms` is a dict whose values are fully configured GridSearchCV\n",
    "        objects, ready to `.fit()` inside the evaluate_cv() function.\n",
    "\"\"\"\n",
    "algorithms = {}\n",
    "for alg in base_estimators:\n",
    "    algorithms[alg] = GridSearchCV(\n",
    "        estimator  = base_estimators[alg],\n",
    "        param_grid = param_grids[alg],\n",
    "        cv         = kf, \n",
    "        n_jobs     = -1,                 # Use all CPU cores\n",
    "        scoring    = scoring_dict,       # Store all metrics\n",
    "        refit      = 'recall_1'          # Optimize for recall of class 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5f4ef559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cv(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Outer 5-fold cross-validation for model-selection and performance\n",
    "    estimation.\n",
    "\n",
    "      • Each outer fold:\n",
    "          1. resamples ONLY the training split (SMOTE + undersampling)\n",
    "          2. runs the inner GridSearchCV (optimising recall_1, recording all metrics)\n",
    "          3. evaluates the winning model on the held-out validation split\n",
    "\n",
    "      • After the outer loop finishes, every GridSearchCV is refit on the\n",
    "        entire resampled training set so that `best_estimator_` has seen all\n",
    "        available data.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary : pd.DataFrame        rows = metric (mean / std),  cols = model\n",
    "    best_params_overall : dict    {model_name: final best hyper-params}\n",
    "    \"\"\"\n",
    "\n",
    "    # Record the start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Initialize dictionaries to store best hyperparameters and best grid-search scores for each fold\n",
    "    fold_scores     = {m: {alg: [] for alg in algorithms} for m in scoring_dict}\n",
    "    best_params_all = {alg: [] for alg in algorithms}\n",
    "    best_scores_all = {alg: [] for alg in algorithms}\n",
    "    # Candidate counts for logs\n",
    "    candidates = {alg: np.prod([len(v) for v in param_grids[alg].values()]) for alg in param_grids}\n",
    "\n",
    "    # Outer loop\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train, y_train), 1):\n",
    "        # Allocate train and validation data\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Resample only the training data (no leakage of validation data)\n",
    "        X_train_fold_res, y_train_fold_res = resample_pipe.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "        # Iterate through each algorithm (each wrapped with GridSearchCV)\n",
    "        for alg, gs in algorithms.items():\n",
    "            print(f\"Fold {fold_idx} – {alg}: {candidates[alg]} candidates\")\n",
    "            # Inner GridSearchCV for hyper-parameter tuning\n",
    "            gs.fit(X_train_fold_res, y_train_fold_res)\n",
    "            \n",
    "            # Keep track of the best hyperparameters and the best score from grid-search for this outer fold\n",
    "            best_params_all[alg].append(gs.best_params_)\n",
    "            best_scores_all[alg].append(gs.best_score_)\n",
    "            \n",
    "            # Evaluate the winning model on the held-out fold\n",
    "            # Make predictions for the validation data (using the best estimator found)\n",
    "            y_pred = gs.predict(X_val_fold)\n",
    "            y_prob = gs.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "            def calc(metric_name):\n",
    "                \"\"\"\n",
    "                Compute <metric_name> on the current outer-fold validation split.\n",
    "                Raises ValueError if the key is not recognised.\n",
    "                \"\"\"\n",
    "\n",
    "                # Probability-based metrics\n",
    "                if   metric_name == \"roc_auc\":\n",
    "                    return roc_auc_score(y_val_fold, y_prob)\n",
    "                elif metric_name == \"pr_auc\":\n",
    "                    return average_precision_score(y_val_fold, y_prob)\n",
    "\n",
    "                # Class-agnostic metrics\n",
    "                elif metric_name == \"balanced_acc\":\n",
    "                    return balanced_accuracy_score(y_val_fold, y_pred)\n",
    "\n",
    "                # Class-specific metrics must end with _0 or _1\n",
    "                if not metric_name.endswith((\"_0\", \"_1\")):\n",
    "                    raise ValueError(f\"Unknown metric name: {metric_name}\")\n",
    "\n",
    "                # Class-specific metrics\n",
    "                lbl  = 1 if metric_name.endswith(\"_1\") else 0\n",
    "                base = metric_name.split(\"_\")[0]            # recall | precision | f1 | f2\n",
    "\n",
    "                if   base == \"recall\":\n",
    "                    return recall_score(y_val_fold, y_pred, pos_label=lbl, zero_division=0)\n",
    "                elif base == \"precision\":\n",
    "                    return precision_score(y_val_fold, y_pred, pos_label=lbl, zero_division=0)\n",
    "                elif base == \"f1\":\n",
    "                    return f1_score(y_val_fold, y_pred, pos_label=lbl, zero_division=0)\n",
    "                elif base == \"f2\":\n",
    "                    return fbeta_score(y_val_fold, y_pred, beta=2, pos_label=lbl, zero_division=0)\n",
    "\n",
    "                # Prefix wasn’t one of the recognised options\n",
    "                raise ValueError(f\"Unknown metric name: {metric_name}\")\n",
    "\n",
    "            for m in scoring_dict:\n",
    "                fold_scores[m][alg].append(calc(m))       \n",
    "\n",
    "    # Create a DataFrame summary table with the mean and standard deviation of each algorithm's performance across CV folds\n",
    "    metrics_summary = {}\n",
    "    for m in scoring_dict:\n",
    "        metrics_summary[f\"{m} (mean)\"] = {alg: np.mean(metrics) for alg, metrics in fold_scores[m].items()}\n",
    "        metrics_summary[f\"{m} (std)\"]  = {alg: np.std(metrics) for alg, metrics in fold_scores[m].items()}\n",
    "    summary = pd.DataFrame(metrics_summary).T   # Metrics in rows\n",
    "\n",
    "    \"\"\"\n",
    "    Final refit on all training data\n",
    "\n",
    "    Without the refit: After cross-validation finishes, each GridSearchCV object is fitted on only the 4 folds used in the final CV iteration.\n",
    "    That leaves 20 % of the training data (the fold that happened to be “validation” in that iteration) completely unseen by the model later evaluated on X_test.\n",
    "\n",
    "    With the refit: Train a fresh model—using the same best hyper-parameters found during CV on the entire training set (after SMOTE + undersampling).\n",
    "    This guarantees that the test-set assessment uses a model that has seen all training data without leaking any information from the test set.\n",
    "    \"\"\"\n",
    "    X_full_res, y_full_res = resample_pipe.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Refit each GridSearchCV on the entire resampled training set\n",
    "    # This ensures that the best estimator is trained with all available data\n",
    "    for gs in algorithms.values():\n",
    "        gs.fit(X_full_res, y_full_res)\n",
    "\n",
    "    # Store the best hyperparameters for each algorithm after refitting on the entire training set\n",
    "    best_params_overall = {alg: gs.best_params_ for alg, gs in algorithms.items()}        \n",
    "\n",
    "    # Record the end time and print total time taken\n",
    "    end_time = time.time()\n",
    "    print(f\"\\Total CV time: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    return summary, best_params_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "f9b6d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models using cross-validation\n",
    "# Performs the outer cross-validation, tune hyperparameters, and evaluate the models on the validation set\n",
    "# Returns a summary of the metrics and the best hyperparameters for each model\n",
    "# cv_summary, best_params = evaluate_cv(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f906411c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cross-validated metrics ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Cross-validated metrics ===\")\n",
    "# display(cv_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "667192b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final best hyper-parameters ===\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Final best hyper-parameters ===\")\n",
    "# for alg, params in best_params.items():\n",
    "#     print(f\"{alg}: {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "f65c9f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(algorithms, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Final assessment on the held-out test set.\n",
    "        • Uses the same `scoring_dict` as cross-validation\n",
    "        • Returns a score results DataFrame:  rows = metrics, cols = model names\n",
    "    \"\"\"\n",
    "    # Prepare an empty metric → model → value mapping\n",
    "    scores = {m: {} for m in scoring_dict}\n",
    "\n",
    "    for model_name, gs in algorithms.items():\n",
    "        est   = gs.best_estimator_\n",
    "        y_hat = est.predict(X_test)\n",
    "        y_prob = (est.predict_proba(X_test)[:, 1] if hasattr(est, \"predict_proba\") else None)\n",
    "\n",
    "        def calc(metric_name):\n",
    "            \"\"\"\n",
    "            Compute <metric_name> on the current outer-fold validation split.\n",
    "            Raises ValueError if the key is not recognised.\n",
    "            \"\"\"\n",
    "\n",
    "            # Probability-based metrics\n",
    "            if   metric_name == \"roc_auc\":\n",
    "                return roc_auc_score(y_test, y_prob)\n",
    "            elif metric_name == \"pr_auc\":\n",
    "                return average_precision_score(y_test, y_prob)\n",
    "\n",
    "            # Class-agnostic metrics\n",
    "            elif metric_name == \"balanced_acc\":\n",
    "                return balanced_accuracy_score(y_test, y_hat)\n",
    "\n",
    "            # Class-specific metrics must end with _0 or _1\n",
    "            if not metric_name.endswith((\"_0\", \"_1\")):\n",
    "                raise ValueError(f\"Unknown metric name: {metric_name}\")\n",
    "\n",
    "            # Class-specific metrics\n",
    "            lbl  = 1 if metric_name.endswith(\"_1\") else 0\n",
    "            base = metric_name.split(\"_\")[0]            # recall | precision | f1 | f2\n",
    "\n",
    "            if   base == \"recall\":\n",
    "                return recall_score(y_test, y_hat, pos_label=lbl, zero_division=0)\n",
    "            elif base == \"precision\":\n",
    "                return precision_score(y_test, y_hat, pos_label=lbl, zero_division=0)\n",
    "            elif base == \"f1\":\n",
    "                return f1_score(y_test, y_hat, pos_label=lbl, zero_division=0)\n",
    "            elif base == \"f2\":\n",
    "                return fbeta_score(y_test, y_hat, beta=2, pos_label=lbl, zero_division=0)\n",
    "\n",
    "            # Prefix wasn’t one of the recognised options\n",
    "            raise ValueError(f\"Unknown metric name: {metric_name}\")  \n",
    "\n",
    "        # Fill the scores dict\n",
    "        for m in scoring_dict:\n",
    "            scores[m][model_name] = calc(m)\n",
    "\n",
    "    # Return Dataframe (metrics as rows)\n",
    "    return pd.DataFrame(scores).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "36de08c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_test = test_model(algorithms, X_test, y_test)\n",
    "# display(results_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "22a3f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix for each algorithm on the test set\n",
    "# Shows the number of true positives, true negatives, false positives, and false negatives\n",
    "# for name, gs in algorithms.items():\n",
    "#     y_pred = gs.best_estimator_.predict(X_test)\n",
    "#     # plt.cm.Blues is a colormap that ranges from light blue (few values) to dark blue (many values)\n",
    "#     ConfusionMatrixDisplay.from_predictions(y_test, y_pred, labels=[0,1], colorbar=True, cmap=plt.cm.Blues)\n",
    "#     plt.title(name)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "1a81f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSITIVE_ATTR = 'GENDER'      # 1 = feminino, 0 = masculino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e483f6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_RF_PARAMS = {'class_weight': {0: 1, 1: 3},\n",
    "                  'max_depth': 10,\n",
    "                  'min_samples_split': 30,\n",
    "                  'n_estimators': 200,\n",
    "                  'random_state': 0,\n",
    "                  'n_jobs': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "15458852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_opportunity(y_true: pd.Series,\n",
    "                      y_pred: np.ndarray,\n",
    "                      a: pd.Series):\n",
    "    \"\"\"\n",
    "    Calcula a métrica de Oportunidade Igual:\n",
    "        p1 = P(ŷ = 1 | y = 1, a = 1)\n",
    "        p2 = P(ŷ = 1 | y = 1, a = 0)\n",
    "        diff = p1 - p2\n",
    "    Retorna p1, p2 e diff.\n",
    "    \"\"\"\n",
    "    # Máscara apenas para exemplos realmente positivos\n",
    "    pos_mask = (y_true == 1)\n",
    "\n",
    "    # Evita divisão por zero caso não haja positivos num dos grupos\n",
    "    def _safe_mean(mask):\n",
    "        return (y_pred[mask].mean() if mask.any() else np.nan)\n",
    "\n",
    "    p1 = _safe_mean(pos_mask & (a == 1))\n",
    "    p2 = _safe_mean(pos_mask & (a == 0))\n",
    "    return p1, p2, abs(p1 - p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f2ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COM coluna de gênero ===\n",
      "Treino: feminino=0.865  masculino=0.942  diff=0.077\n",
      "Teste : feminino=0.765  masculino=0.851  diff=0.087\n",
      "\n",
      "=== SEM coluna de gênero ===\n",
      "Treino: feminino=0.893  masculino=0.921  diff=0.028\n",
      "Teste : feminino=0.817  masculino=0.828  diff=0.011\n",
      "\n",
      "--- RF COM gênero – Teste ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.48      0.64      9341\n",
      "           1       0.11      0.81      0.20       768\n",
      "\n",
      "    accuracy                           0.51     10109\n",
      "   macro avg       0.54      0.65      0.42     10109\n",
      "weighted avg       0.90      0.51      0.61     10109\n",
      "\n",
      "Balanced Accuracy: 0.6462671287870678\n",
      "\n",
      "--- RF SEM gênero – Teste ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.46      0.62      9341\n",
      "           1       0.11      0.82      0.20       768\n",
      "\n",
      "    accuracy                           0.48     10109\n",
      "   macro avg       0.54      0.64      0.41     10109\n",
      "weighted avg       0.90      0.48      0.59     10109\n",
      "\n",
      "Balanced Accuracy: 0.6398600033900724\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pequeno utilitário: devolve apenas as features usadas no treinamento\n",
    "def _base_features(df, drop_sensitive=False):                      ### NOVO ###\n",
    "    \"\"\"\n",
    "    Remove colunas que começam com 'y_pred' (e a sensível, se pedido).\n",
    "    Isso garante que o shape das features bate com o usado no .fit().\n",
    "    \"\"\"\n",
    "    cols_out = [c for c in df.columns if c.startswith('y_pred')]\n",
    "    if drop_sensitive:\n",
    "        cols_out.append(SENSITIVE_ATTR)\n",
    "    return df.drop(columns=cols_out, errors='ignore')\n",
    "\n",
    "\n",
    "# 2. Random-Forest **com** coluna de gênero\n",
    "X_train_res, y_train_res = resample_pipe.fit_resample(_base_features(X_train), y_train)   ### ALTERADO ###\n",
    "rf_with_gender = RandomForestClassifier(**BEST_RF_PARAMS)\n",
    "rf_with_gender.fit(X_train_res, y_train_res)\n",
    "\n",
    "# previsões ≠ colunas usadas no treino → limpe antes de chamar .predict\n",
    "X_train['y_pred_rf'] = rf_with_gender.predict(_base_features(X_train))   ### ALTERADO ###\n",
    "X_test ['y_pred_rf'] = rf_with_gender.predict(_base_features(X_test))    ### ALTERADO ###\n",
    "\n",
    "# Calcula a métrica de Oportunidade Igual\n",
    "p1_train, p2_train, diff_train = equal_opportunity(y_train,\n",
    "                                                   X_train['y_pred_rf'].values,\n",
    "                                                   X_train[SENSITIVE_ATTR])\n",
    "\n",
    "p1_test,  p2_test,  diff_test  = equal_opportunity(y_test,\n",
    "                                                   X_test['y_pred_rf'].values,\n",
    "                                                   X_test[SENSITIVE_ATTR])\n",
    "\n",
    "print(\"=== COM coluna de gênero ===\")\n",
    "print(f\"Treino: feminino={p1_train:.3f}  masculino={p2_train:.3f}  diff={diff_train:.3f}\")\n",
    "print(f\"Teste : feminino={p1_test :.3f}  masculino={p2_test :.3f}  diff={diff_test :.3f}\")\n",
    "\n",
    "\n",
    "# 3. Remove coluna sensível e refaz\n",
    "X_train_no_gen = _base_features(X_train, drop_sensitive=True)      ### ALTERADO ###\n",
    "X_test_no_gen  = _base_features(X_test , drop_sensitive=True)      ### ALTERADO ###\n",
    "\n",
    "X_train_res2, y_train_res2 = resample_pipe.fit_resample(X_train_no_gen, y_train)\n",
    "rf_no_gender = RandomForestClassifier(**BEST_RF_PARAMS)\n",
    "rf_no_gender.fit(X_train_res2, y_train_res2)\n",
    "\n",
    "X_train['y_pred_rf_nogen'] = rf_no_gender.predict(X_train_no_gen)\n",
    "X_test ['y_pred_rf_nogen'] = rf_no_gender.predict(X_test_no_gen)\n",
    "\n",
    "# Métrica de Oportunidade Igual novamente\n",
    "p1_train_ng, p2_train_ng, diff_train_ng = equal_opportunity(\n",
    "    y_train, X_train['y_pred_rf_nogen'].values, X_train[SENSITIVE_ATTR])\n",
    "\n",
    "p1_test_ng,  p2_test_ng,  diff_test_ng  = equal_opportunity(\n",
    "    y_test,  X_test ['y_pred_rf_nogen'].values, X_test [SENSITIVE_ATTR])\n",
    "\n",
    "print(\"\\n=== SEM coluna de gênero ===\")\n",
    "print(f\"Treino: feminino={p1_train_ng:.3f}  masculino={p2_train_ng:.3f}  diff={diff_train_ng:.3f}\")\n",
    "print(f\"Teste : feminino={p1_test_ng :.3f}  masculino={p2_test_ng :.3f}  diff={diff_test_ng :.3f}\")\n",
    "\n",
    "\n",
    "# 4. Relatórios de desempenho\n",
    "\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "\n",
    "def show_perf(estimator, X, y, label, drop_sensitive=False):       ### ALTERADO ###\n",
    "    feats = _base_features(X, drop_sensitive=drop_sensitive)\n",
    "    y_hat = estimator.predict(feats)\n",
    "    print(f\"\\n--- {label} ---\")\n",
    "    print(classification_report(y, y_hat, zero_division=0))\n",
    "    print(\"Balanced Accuracy:\", balanced_accuracy_score(y, y_hat))\n",
    "\n",
    "show_perf(rf_with_gender, X_test, y_test, \"RF COM gênero – Teste\")\n",
    "show_perf(rf_no_gender,  X_test, y_test, \"RF SEM gênero – Teste\", drop_sensitive=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
